{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "\n",
    "Given a Bankâ€™s customer information, can we build a classifier which can\n",
    "determine whether they will leave or not?\n",
    "\n",
    "# Context:\n",
    "\n",
    "Businesses like banks which provide service have to worry about problem\n",
    "of 'Churn' i.e. customers leaving and joining another service provider. It is\n",
    "important to understand which aspects of the service influence a\n",
    "customer's decision in this regard. Management can concentrate efforts\n",
    "on improvement of service, keeping in mind these priorities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps and Milestones (100%):\n",
    "Setup Environment and Load Necessary Packages (5%)\n",
    "Data Preparation (40%)\n",
    "  o Loading Data (5%)\n",
    "  o Cleaning Data (10%)\n",
    "  o Data Representation & Feature Engineering (If Any) (15%)\n",
    "  o Creating Train and Validation Set (10%)\n",
    "Model Creation (30%)\n",
    "  o Write & Configure Model (10%)\n",
    "  o Compile Model (10%)\n",
    "  o Build Model & Checking Summary (10%)\n",
    "Training and Evaluation (25%)\n",
    "  o Run Multiple Experiments (10%)\n",
    "  o Reason & Visualize Model Performance (5%)\n",
    "  o Evaluate Model on Test Set (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment and Load Necessary Packages (5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import BatchNormalization  \n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (40%)<br>\n",
    "o Loading Data (5%)<br>\n",
    "o Cleaning Data (10%)<br>\n",
    "o Data Representation & Feature Engineering (If Any) (15%)<br>\n",
    "o Creating Train and Validation Set (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('bank.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RowNumber, CustomerId, Surname are not important, so we will drop these columns \n",
    "df.drop(['RowNumber','CustomerId','Surname'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Geography'] = df['Geography'].astype('category')\n",
    "df['Gender'] = df['Gender'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Geography','Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  \n",
       "3                  0                0              1            0  \n",
       "4                  0                1              1            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited',axis=1).values\n",
    "y = df['Exited'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exited'].value_counts() # This is imbalnced dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(X_train)\n",
    "Xs_train = sc.transform(X_train)\n",
    "Xs_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from integers to floats\n",
    "Xs_train = Xs_train.astype('float32')\n",
    "Xs_test = Xs_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 13), (2000, 13), (8000,), (2000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train.shape,Xs_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([6378, 1622], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train,return_counts=True) #For training, 0 and 1 are almost equally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([1585,  415], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=SMOTE()\n",
    "Xs_train, y_train = sm.fit_sample(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([6378, 6378], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12756, 13), (2000, 13))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train.shape,Xs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = keras.utils.to_categorical(y_train, 2)\n",
    "ytest = keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23082039, -0.9444998 , -0.70174205, ..., -0.5727314 ,\n",
       "        -0.9150907 ,  0.9150907 ],\n",
       "       [-0.25150913, -0.9444998 , -0.35520276, ..., -0.5727314 ,\n",
       "         1.0927879 , -1.0927879 ],\n",
       "       [-0.3963303 ,  0.77498704,  0.33787578, ..., -0.5727314 ,\n",
       "         1.0927879 , -1.0927879 ],\n",
       "       ...,\n",
       "       [-1.9575125 ,  0.2805743 , -0.04923887, ...,  1.7460192 ,\n",
       "         1.0927879 , -1.0927879 ],\n",
       "       [ 0.9062327 , -0.63070077, -0.15708892, ..., -0.5727314 ,\n",
       "        -0.9150907 ,  0.9150907 ],\n",
       "       [-1.0718747 , -0.36742648,  1.3774936 , ..., -0.5727314 ,\n",
       "        -0.9150907 ,  0.9150907 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation (30%)<br>\n",
    "  o Write & Configure Model (10%)<br>\n",
    "  o Compile Model (10%)<br>\n",
    "  o Build Model & Checking Summary (10%)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Define model architecture\n",
    "\n",
    "wt_init=tf.keras.initializers.he_normal(seed=None)\n",
    "\n",
    "model.add(Flatten(input_shape = (Xs_train.shape[1], )))\n",
    "model.add(Dense(256, activation = 'relu',kernel_initializer = wt_init,kernel_constraint = max_norm(2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.2)) \n",
    "model.add(Dense(128, activation ='relu',kernel_initializer = wt_init,kernel_constraint = max_norm(2)))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(64, activation ='relu',kernel_initializer = wt_init,kernel_constraint = max_norm(2)))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(64, activation ='relu',kernel_initializer = wt_init,kernel_constraint = max_norm(2)))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(64, activation ='relu',kernel_initializer = wt_init,kernel_constraint = max_norm(2)))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001,decay=1e-6)\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 256)               3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 54,210\n",
      "Trainable params: 53,698\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11480 samples, validate on 1276 samples\n",
      "Epoch 1/800\n",
      "11480/11480 [==============================] - 3s 273us/sample - loss: 2.1713 - accuracy: 0.4449 - val_loss: 0.3725 - val_accuracy: 0.8558\n",
      "Epoch 2/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 1.5288 - accuracy: 0.4439 - val_loss: 0.7216 - val_accuracy: 0.5823\n",
      "Epoch 3/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 1.0995 - accuracy: 0.4748 - val_loss: 1.1344 - val_accuracy: 0.2727\n",
      "Epoch 4/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.9199 - accuracy: 0.5139 - val_loss: 1.4627 - val_accuracy: 0.1042\n",
      "Epoch 5/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.8755 - accuracy: 0.5582 - val_loss: 1.6163 - val_accuracy: 0.0549\n",
      "Epoch 6/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.8844 - accuracy: 0.5788 - val_loss: 1.6072 - val_accuracy: 0.0470\n",
      "Epoch 7/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.8750 - accuracy: 0.5882 - val_loss: 1.4924 - val_accuracy: 0.0619\n",
      "Epoch 8/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.8316 - accuracy: 0.6015 - val_loss: 1.3312 - val_accuracy: 0.1074\n",
      "Epoch 9/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.7949 - accuracy: 0.6124 - val_loss: 1.1613 - val_accuracy: 0.2139\n",
      "Epoch 10/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.7447 - accuracy: 0.6334 - val_loss: 1.0045 - val_accuracy: 0.3127\n",
      "Epoch 11/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.6956 - accuracy: 0.6430 - val_loss: 0.8707 - val_accuracy: 0.4099\n",
      "Epoch 12/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.6782 - accuracy: 0.6537 - val_loss: 0.7610 - val_accuracy: 0.5039\n",
      "Epoch 13/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.6476 - accuracy: 0.6584 - val_loss: 0.6745 - val_accuracy: 0.5619\n",
      "Epoch 14/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.6513 - accuracy: 0.6509 - val_loss: 0.6093 - val_accuracy: 0.6183\n",
      "Epoch 15/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.6415 - accuracy: 0.6575 - val_loss: 0.5637 - val_accuracy: 0.6693\n",
      "Epoch 16/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.6423 - accuracy: 0.6634 - val_loss: 0.5343 - val_accuracy: 0.6951\n",
      "Epoch 17/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.6406 - accuracy: 0.6626 - val_loss: 0.5180 - val_accuracy: 0.7116\n",
      "Epoch 18/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.6347 - accuracy: 0.6656 - val_loss: 0.5122 - val_accuracy: 0.7155\n",
      "Epoch 19/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.6362 - accuracy: 0.6686 - val_loss: 0.5140 - val_accuracy: 0.7132\n",
      "Epoch 20/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.6246 - accuracy: 0.6719 - val_loss: 0.5216 - val_accuracy: 0.7085\n",
      "Epoch 21/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.6128 - accuracy: 0.6747 - val_loss: 0.5337 - val_accuracy: 0.6944\n",
      "Epoch 22/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.6070 - accuracy: 0.6873 - val_loss: 0.5487 - val_accuracy: 0.6748\n",
      "Epoch 23/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.5907 - accuracy: 0.6944 - val_loss: 0.5650 - val_accuracy: 0.6567\n",
      "Epoch 24/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5953 - accuracy: 0.6944 - val_loss: 0.5811 - val_accuracy: 0.6426\n",
      "Epoch 25/800\n",
      "11480/11480 [==============================] - 0s 33us/sample - loss: 0.5854 - accuracy: 0.7019 - val_loss: 0.5961 - val_accuracy: 0.6340\n",
      "Epoch 26/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5818 - accuracy: 0.7039 - val_loss: 0.6086 - val_accuracy: 0.6254\n",
      "Epoch 27/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.5811 - accuracy: 0.7032 - val_loss: 0.6182 - val_accuracy: 0.6191\n",
      "Epoch 28/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.5708 - accuracy: 0.7151 - val_loss: 0.6240 - val_accuracy: 0.6144\n",
      "Epoch 29/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.5649 - accuracy: 0.7160 - val_loss: 0.6257 - val_accuracy: 0.6152\n",
      "Epoch 30/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5676 - accuracy: 0.7167 - val_loss: 0.6236 - val_accuracy: 0.6230\n",
      "Epoch 31/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.5627 - accuracy: 0.7184 - val_loss: 0.6184 - val_accuracy: 0.6254\n",
      "Epoch 32/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5568 - accuracy: 0.7218 - val_loss: 0.6105 - val_accuracy: 0.6285\n",
      "Epoch 33/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.5569 - accuracy: 0.7223 - val_loss: 0.6002 - val_accuracy: 0.6387\n",
      "Epoch 34/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.5560 - accuracy: 0.7213 - val_loss: 0.5886 - val_accuracy: 0.6513\n",
      "Epoch 35/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5484 - accuracy: 0.7206 - val_loss: 0.5759 - val_accuracy: 0.6614\n",
      "Epoch 36/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.5428 - accuracy: 0.7299 - val_loss: 0.5628 - val_accuracy: 0.6771\n",
      "Epoch 37/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5464 - accuracy: 0.7259 - val_loss: 0.5501 - val_accuracy: 0.6889\n",
      "Epoch 38/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.5378 - accuracy: 0.7327 - val_loss: 0.5383 - val_accuracy: 0.6983\n",
      "Epoch 39/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.5321 - accuracy: 0.7351 - val_loss: 0.5272 - val_accuracy: 0.7092\n",
      "Epoch 40/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.5366 - accuracy: 0.7348 - val_loss: 0.5174 - val_accuracy: 0.7171\n",
      "Epoch 41/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.5265 - accuracy: 0.7406 - val_loss: 0.5089 - val_accuracy: 0.7210\n",
      "Epoch 42/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.5249 - accuracy: 0.7363 - val_loss: 0.5018 - val_accuracy: 0.7234\n",
      "Epoch 43/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.5226 - accuracy: 0.7440 - val_loss: 0.4961 - val_accuracy: 0.7288\n",
      "Epoch 44/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.5216 - accuracy: 0.7457 - val_loss: 0.4920 - val_accuracy: 0.7343\n",
      "Epoch 45/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5225 - accuracy: 0.7435 - val_loss: 0.4892 - val_accuracy: 0.7367\n",
      "Epoch 46/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5149 - accuracy: 0.7483 - val_loss: 0.4878 - val_accuracy: 0.7359\n",
      "Epoch 47/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.5206 - accuracy: 0.7411 - val_loss: 0.4876 - val_accuracy: 0.7343\n",
      "Epoch 48/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5147 - accuracy: 0.7487 - val_loss: 0.4886 - val_accuracy: 0.7359\n",
      "Epoch 49/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.5096 - accuracy: 0.7493 - val_loss: 0.4906 - val_accuracy: 0.7335\n",
      "Epoch 50/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.5085 - accuracy: 0.7506 - val_loss: 0.4934 - val_accuracy: 0.7367\n",
      "Epoch 51/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.5060 - accuracy: 0.7567 - val_loss: 0.4964 - val_accuracy: 0.7343\n",
      "Epoch 52/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.5049 - accuracy: 0.7554 - val_loss: 0.4993 - val_accuracy: 0.7288\n",
      "Epoch 53/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.5066 - accuracy: 0.7564 - val_loss: 0.5018 - val_accuracy: 0.7304\n",
      "Epoch 54/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.5047 - accuracy: 0.7535 - val_loss: 0.5037 - val_accuracy: 0.7296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.5012 - accuracy: 0.7568 - val_loss: 0.5049 - val_accuracy: 0.7265\n",
      "Epoch 56/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4977 - accuracy: 0.7590 - val_loss: 0.5054 - val_accuracy: 0.7249\n",
      "Epoch 57/800\n",
      "11480/11480 [==============================] - 0s 33us/sample - loss: 0.4954 - accuracy: 0.7579 - val_loss: 0.5051 - val_accuracy: 0.7249\n",
      "Epoch 58/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4994 - accuracy: 0.7600 - val_loss: 0.5041 - val_accuracy: 0.7241\n",
      "Epoch 59/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4942 - accuracy: 0.7598 - val_loss: 0.5026 - val_accuracy: 0.7241\n",
      "Epoch 60/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4959 - accuracy: 0.7641 - val_loss: 0.5008 - val_accuracy: 0.7226\n",
      "Epoch 61/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4928 - accuracy: 0.7593 - val_loss: 0.4985 - val_accuracy: 0.7226\n",
      "Epoch 62/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4903 - accuracy: 0.7645 - val_loss: 0.4960 - val_accuracy: 0.7234\n",
      "Epoch 63/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4889 - accuracy: 0.7660 - val_loss: 0.4931 - val_accuracy: 0.7273\n",
      "Epoch 64/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4909 - accuracy: 0.7651 - val_loss: 0.4899 - val_accuracy: 0.7265\n",
      "Epoch 65/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4906 - accuracy: 0.7631 - val_loss: 0.4868 - val_accuracy: 0.7265\n",
      "Epoch 66/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4806 - accuracy: 0.7706 - val_loss: 0.4837 - val_accuracy: 0.7328\n",
      "Epoch 67/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4804 - accuracy: 0.7680 - val_loss: 0.4811 - val_accuracy: 0.7304\n",
      "Epoch 68/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4846 - accuracy: 0.7689 - val_loss: 0.4785 - val_accuracy: 0.7328\n",
      "Epoch 69/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4770 - accuracy: 0.7677 - val_loss: 0.4766 - val_accuracy: 0.7367\n",
      "Epoch 70/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4784 - accuracy: 0.7726 - val_loss: 0.4756 - val_accuracy: 0.7359\n",
      "Epoch 71/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4769 - accuracy: 0.7701 - val_loss: 0.4752 - val_accuracy: 0.7359\n",
      "Epoch 72/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4801 - accuracy: 0.7703 - val_loss: 0.4754 - val_accuracy: 0.7351\n",
      "Epoch 73/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4760 - accuracy: 0.7719 - val_loss: 0.4756 - val_accuracy: 0.7359\n",
      "Epoch 74/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.4768 - val_accuracy: 0.7343\n",
      "Epoch 75/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4740 - accuracy: 0.7706 - val_loss: 0.4781 - val_accuracy: 0.7343\n",
      "Epoch 76/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4753 - accuracy: 0.7706 - val_loss: 0.4797 - val_accuracy: 0.7328\n",
      "Epoch 77/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4767 - accuracy: 0.7722 - val_loss: 0.4813 - val_accuracy: 0.7304\n",
      "Epoch 78/800\n",
      "11480/11480 [==============================] - 0s 34us/sample - loss: 0.4731 - accuracy: 0.7729 - val_loss: 0.4822 - val_accuracy: 0.7296\n",
      "Epoch 79/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4703 - accuracy: 0.7722 - val_loss: 0.4826 - val_accuracy: 0.7312\n",
      "Epoch 80/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4732 - accuracy: 0.7783 - val_loss: 0.4828 - val_accuracy: 0.7320\n",
      "Epoch 81/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4699 - accuracy: 0.7733 - val_loss: 0.4831 - val_accuracy: 0.7312\n",
      "Epoch 82/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4750 - accuracy: 0.7744 - val_loss: 0.4825 - val_accuracy: 0.7335\n",
      "Epoch 83/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.4743 - accuracy: 0.7776 - val_loss: 0.4814 - val_accuracy: 0.7351\n",
      "Epoch 84/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4687 - accuracy: 0.7771 - val_loss: 0.4802 - val_accuracy: 0.7359\n",
      "Epoch 85/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.4791 - val_accuracy: 0.7398\n",
      "Epoch 86/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4667 - accuracy: 0.7795 - val_loss: 0.4776 - val_accuracy: 0.7429\n",
      "Epoch 87/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4656 - accuracy: 0.7756 - val_loss: 0.4765 - val_accuracy: 0.7429\n",
      "Epoch 88/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4692 - accuracy: 0.7775 - val_loss: 0.4751 - val_accuracy: 0.7437\n",
      "Epoch 89/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4625 - accuracy: 0.7807 - val_loss: 0.4737 - val_accuracy: 0.7453\n",
      "Epoch 90/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4652 - accuracy: 0.7775 - val_loss: 0.4724 - val_accuracy: 0.7469\n",
      "Epoch 91/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4649 - accuracy: 0.7829 - val_loss: 0.4711 - val_accuracy: 0.7484\n",
      "Epoch 92/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4647 - accuracy: 0.7821 - val_loss: 0.4707 - val_accuracy: 0.7476\n",
      "Epoch 93/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.4616 - accuracy: 0.7867 - val_loss: 0.4706 - val_accuracy: 0.7461\n",
      "Epoch 94/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4650 - accuracy: 0.7814 - val_loss: 0.4704 - val_accuracy: 0.7461\n",
      "Epoch 95/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4576 - accuracy: 0.7856 - val_loss: 0.4704 - val_accuracy: 0.7445\n",
      "Epoch 96/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4620 - accuracy: 0.7824 - val_loss: 0.4710 - val_accuracy: 0.7445\n",
      "Epoch 97/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4584 - accuracy: 0.7828 - val_loss: 0.4716 - val_accuracy: 0.7469\n",
      "Epoch 98/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4573 - accuracy: 0.7839 - val_loss: 0.4720 - val_accuracy: 0.7429\n",
      "Epoch 99/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4565 - accuracy: 0.7834 - val_loss: 0.4716 - val_accuracy: 0.7429\n",
      "Epoch 100/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4549 - accuracy: 0.7895 - val_loss: 0.4709 - val_accuracy: 0.7414\n",
      "Epoch 101/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4538 - accuracy: 0.7831 - val_loss: 0.4698 - val_accuracy: 0.7422\n",
      "Epoch 102/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4550 - accuracy: 0.7861 - val_loss: 0.4688 - val_accuracy: 0.7390\n",
      "Epoch 103/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4593 - accuracy: 0.7881 - val_loss: 0.4678 - val_accuracy: 0.7390\n",
      "Epoch 104/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4512 - accuracy: 0.7881 - val_loss: 0.4665 - val_accuracy: 0.7422\n",
      "Epoch 105/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4555 - accuracy: 0.7864 - val_loss: 0.4654 - val_accuracy: 0.7422\n",
      "Epoch 106/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4518 - accuracy: 0.7855 - val_loss: 0.4637 - val_accuracy: 0.7445\n",
      "Epoch 107/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4520 - accuracy: 0.7875 - val_loss: 0.4619 - val_accuracy: 0.7484\n",
      "Epoch 108/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4491 - accuracy: 0.7883 - val_loss: 0.4610 - val_accuracy: 0.7484\n",
      "Epoch 109/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4477 - accuracy: 0.7899 - val_loss: 0.4598 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4510 - accuracy: 0.7867 - val_loss: 0.4589 - val_accuracy: 0.7500\n",
      "Epoch 111/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4513 - accuracy: 0.7881 - val_loss: 0.4583 - val_accuracy: 0.7524\n",
      "Epoch 112/800\n",
      "11480/11480 [==============================] - 0s 33us/sample - loss: 0.4562 - accuracy: 0.7874 - val_loss: 0.4585 - val_accuracy: 0.7524\n",
      "Epoch 113/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4517 - accuracy: 0.7914 - val_loss: 0.4588 - val_accuracy: 0.7516\n",
      "Epoch 114/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4528 - accuracy: 0.7867 - val_loss: 0.4594 - val_accuracy: 0.7500\n",
      "Epoch 115/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4512 - accuracy: 0.7889 - val_loss: 0.4598 - val_accuracy: 0.7500\n",
      "Epoch 116/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4478 - accuracy: 0.7902 - val_loss: 0.4600 - val_accuracy: 0.7500\n",
      "Epoch 117/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4467 - accuracy: 0.7914 - val_loss: 0.4602 - val_accuracy: 0.7492\n",
      "Epoch 118/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.4484 - accuracy: 0.7938 - val_loss: 0.4600 - val_accuracy: 0.7500\n",
      "Epoch 119/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4471 - accuracy: 0.7902 - val_loss: 0.4596 - val_accuracy: 0.7539\n",
      "Epoch 120/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4478 - accuracy: 0.7859 - val_loss: 0.4591 - val_accuracy: 0.7539\n",
      "Epoch 121/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4470 - accuracy: 0.7955 - val_loss: 0.4580 - val_accuracy: 0.7547\n",
      "Epoch 122/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4455 - accuracy: 0.7902 - val_loss: 0.4570 - val_accuracy: 0.7602\n",
      "Epoch 123/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4472 - accuracy: 0.7906 - val_loss: 0.4561 - val_accuracy: 0.7602\n",
      "Epoch 124/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4471 - accuracy: 0.7871 - val_loss: 0.4553 - val_accuracy: 0.7586\n",
      "Epoch 125/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4406 - accuracy: 0.7936 - val_loss: 0.4542 - val_accuracy: 0.7618\n",
      "Epoch 126/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4453 - accuracy: 0.7918 - val_loss: 0.4533 - val_accuracy: 0.7610\n",
      "Epoch 127/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.4524 - val_accuracy: 0.7618\n",
      "Epoch 128/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.4451 - accuracy: 0.7915 - val_loss: 0.4520 - val_accuracy: 0.7610\n",
      "Epoch 129/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4412 - accuracy: 0.7949 - val_loss: 0.4520 - val_accuracy: 0.7618\n",
      "Epoch 130/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4412 - accuracy: 0.7904 - val_loss: 0.4517 - val_accuracy: 0.7641\n",
      "Epoch 131/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4468 - accuracy: 0.7907 - val_loss: 0.4513 - val_accuracy: 0.7649\n",
      "Epoch 132/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4418 - accuracy: 0.7936 - val_loss: 0.4511 - val_accuracy: 0.7649\n",
      "Epoch 133/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4383 - accuracy: 0.7975 - val_loss: 0.4509 - val_accuracy: 0.7665\n",
      "Epoch 134/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4449 - accuracy: 0.7918 - val_loss: 0.4501 - val_accuracy: 0.7657\n",
      "Epoch 135/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4422 - accuracy: 0.7912 - val_loss: 0.4496 - val_accuracy: 0.7665\n",
      "Epoch 136/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4413 - accuracy: 0.7910 - val_loss: 0.4489 - val_accuracy: 0.7665\n",
      "Epoch 137/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4414 - accuracy: 0.7924 - val_loss: 0.4477 - val_accuracy: 0.7672\n",
      "Epoch 138/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4395 - accuracy: 0.7930 - val_loss: 0.4464 - val_accuracy: 0.7672\n",
      "Epoch 139/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4403 - accuracy: 0.7964 - val_loss: 0.4452 - val_accuracy: 0.7680\n",
      "Epoch 140/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4357 - accuracy: 0.7943 - val_loss: 0.4441 - val_accuracy: 0.7704\n",
      "Epoch 141/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4428 - accuracy: 0.7949 - val_loss: 0.4433 - val_accuracy: 0.7712\n",
      "Epoch 142/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4389 - accuracy: 0.7952 - val_loss: 0.4431 - val_accuracy: 0.7719\n",
      "Epoch 143/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4358 - accuracy: 0.7975 - val_loss: 0.4428 - val_accuracy: 0.7704\n",
      "Epoch 144/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.4427 - val_accuracy: 0.7704\n",
      "Epoch 145/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4353 - accuracy: 0.7963 - val_loss: 0.4420 - val_accuracy: 0.7712\n",
      "Epoch 146/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4377 - accuracy: 0.7954 - val_loss: 0.4408 - val_accuracy: 0.7712\n",
      "Epoch 147/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4354 - accuracy: 0.7954 - val_loss: 0.4396 - val_accuracy: 0.7727\n",
      "Epoch 148/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4363 - accuracy: 0.8025 - val_loss: 0.4384 - val_accuracy: 0.7743\n",
      "Epoch 149/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4355 - accuracy: 0.7975 - val_loss: 0.4367 - val_accuracy: 0.7743\n",
      "Epoch 150/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4367 - accuracy: 0.7965 - val_loss: 0.4355 - val_accuracy: 0.7735\n",
      "Epoch 151/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4290 - accuracy: 0.7997 - val_loss: 0.4349 - val_accuracy: 0.7743\n",
      "Epoch 152/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4362 - accuracy: 0.7963 - val_loss: 0.4346 - val_accuracy: 0.7727\n",
      "Epoch 153/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4338 - accuracy: 0.8010 - val_loss: 0.4349 - val_accuracy: 0.7719\n",
      "Epoch 154/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4299 - accuracy: 0.7979 - val_loss: 0.4354 - val_accuracy: 0.7727\n",
      "Epoch 155/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4316 - accuracy: 0.7981 - val_loss: 0.4356 - val_accuracy: 0.7719\n",
      "Epoch 156/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4286 - accuracy: 0.8003 - val_loss: 0.4354 - val_accuracy: 0.7696\n",
      "Epoch 157/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4352 - val_accuracy: 0.7704\n",
      "Epoch 158/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4299 - accuracy: 0.7977 - val_loss: 0.4344 - val_accuracy: 0.7727\n",
      "Epoch 159/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4289 - accuracy: 0.8012 - val_loss: 0.4333 - val_accuracy: 0.7751\n",
      "Epoch 160/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4296 - accuracy: 0.8010 - val_loss: 0.4320 - val_accuracy: 0.7774\n",
      "Epoch 161/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4312 - accuracy: 0.7998 - val_loss: 0.4306 - val_accuracy: 0.7766\n",
      "Epoch 162/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4317 - accuracy: 0.7965 - val_loss: 0.4290 - val_accuracy: 0.7766\n",
      "Epoch 163/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4293 - accuracy: 0.8026 - val_loss: 0.4283 - val_accuracy: 0.7766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/800\n",
      "11480/11480 [==============================] - 0s 33us/sample - loss: 0.4268 - accuracy: 0.8011 - val_loss: 0.4275 - val_accuracy: 0.7766\n",
      "Epoch 165/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4259 - accuracy: 0.8018 - val_loss: 0.4264 - val_accuracy: 0.7766\n",
      "Epoch 166/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4317 - accuracy: 0.8026 - val_loss: 0.4248 - val_accuracy: 0.7774\n",
      "Epoch 167/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4246 - accuracy: 0.8029 - val_loss: 0.4236 - val_accuracy: 0.7782\n",
      "Epoch 168/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4248 - accuracy: 0.8010 - val_loss: 0.4221 - val_accuracy: 0.7821\n",
      "Epoch 169/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4243 - accuracy: 0.8024 - val_loss: 0.4212 - val_accuracy: 0.7837\n",
      "Epoch 170/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4265 - accuracy: 0.8013 - val_loss: 0.4201 - val_accuracy: 0.7829\n",
      "Epoch 171/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4271 - accuracy: 0.8031 - val_loss: 0.4193 - val_accuracy: 0.7837\n",
      "Epoch 172/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4261 - accuracy: 0.8028 - val_loss: 0.4186 - val_accuracy: 0.7837\n",
      "Epoch 173/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4246 - accuracy: 0.8016 - val_loss: 0.4185 - val_accuracy: 0.7861\n",
      "Epoch 174/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4283 - accuracy: 0.8035 - val_loss: 0.4186 - val_accuracy: 0.7868\n",
      "Epoch 175/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4225 - accuracy: 0.8047 - val_loss: 0.4187 - val_accuracy: 0.7868\n",
      "Epoch 176/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4228 - accuracy: 0.7997 - val_loss: 0.4185 - val_accuracy: 0.7876\n",
      "Epoch 177/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4259 - accuracy: 0.8013 - val_loss: 0.4186 - val_accuracy: 0.7876\n",
      "Epoch 178/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4239 - accuracy: 0.8034 - val_loss: 0.4178 - val_accuracy: 0.7892\n",
      "Epoch 179/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4262 - accuracy: 0.8017 - val_loss: 0.4168 - val_accuracy: 0.7892\n",
      "Epoch 180/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4237 - accuracy: 0.8030 - val_loss: 0.4160 - val_accuracy: 0.7900\n",
      "Epoch 181/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4186 - accuracy: 0.8085 - val_loss: 0.4152 - val_accuracy: 0.7908\n",
      "Epoch 182/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4194 - accuracy: 0.8053 - val_loss: 0.4138 - val_accuracy: 0.7908\n",
      "Epoch 183/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4133 - accuracy: 0.8075 - val_loss: 0.4124 - val_accuracy: 0.7947\n",
      "Epoch 184/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4196 - accuracy: 0.8060 - val_loss: 0.4115 - val_accuracy: 0.7962\n",
      "Epoch 185/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4200 - accuracy: 0.8068 - val_loss: 0.4107 - val_accuracy: 0.7978\n",
      "Epoch 186/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4202 - accuracy: 0.8086 - val_loss: 0.4100 - val_accuracy: 0.7986\n",
      "Epoch 187/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4212 - accuracy: 0.8053 - val_loss: 0.4092 - val_accuracy: 0.7986\n",
      "Epoch 188/800\n",
      "11480/11480 [==============================] - 0s 33us/sample - loss: 0.4204 - accuracy: 0.8081 - val_loss: 0.4081 - val_accuracy: 0.7986\n",
      "Epoch 189/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4217 - accuracy: 0.8054 - val_loss: 0.4077 - val_accuracy: 0.7978\n",
      "Epoch 190/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4138 - accuracy: 0.8078 - val_loss: 0.4080 - val_accuracy: 0.7978\n",
      "Epoch 191/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4173 - accuracy: 0.8070 - val_loss: 0.4080 - val_accuracy: 0.7970\n",
      "Epoch 192/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4239 - accuracy: 0.8071 - val_loss: 0.4089 - val_accuracy: 0.7986\n",
      "Epoch 193/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4185 - accuracy: 0.8057 - val_loss: 0.4099 - val_accuracy: 0.8002\n",
      "Epoch 194/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4166 - accuracy: 0.8055 - val_loss: 0.4105 - val_accuracy: 0.7994\n",
      "Epoch 195/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4139 - accuracy: 0.8079 - val_loss: 0.4108 - val_accuracy: 0.7970\n",
      "Epoch 196/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4187 - accuracy: 0.8069 - val_loss: 0.4104 - val_accuracy: 0.7970\n",
      "Epoch 197/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4155 - accuracy: 0.8098 - val_loss: 0.4092 - val_accuracy: 0.7962\n",
      "Epoch 198/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4146 - accuracy: 0.8048 - val_loss: 0.4072 - val_accuracy: 0.7970\n",
      "Epoch 199/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4185 - accuracy: 0.8055 - val_loss: 0.4051 - val_accuracy: 0.7978\n",
      "Epoch 200/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4133 - accuracy: 0.8097 - val_loss: 0.4031 - val_accuracy: 0.7978\n",
      "Epoch 201/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4190 - accuracy: 0.8060 - val_loss: 0.4010 - val_accuracy: 0.7986\n",
      "Epoch 202/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4166 - accuracy: 0.8062 - val_loss: 0.3999 - val_accuracy: 0.8009\n",
      "Epoch 203/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4156 - accuracy: 0.8057 - val_loss: 0.3992 - val_accuracy: 0.8017\n",
      "Epoch 204/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4161 - accuracy: 0.8110 - val_loss: 0.3997 - val_accuracy: 0.8025\n",
      "Epoch 205/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4120 - accuracy: 0.8092 - val_loss: 0.4001 - val_accuracy: 0.8041\n",
      "Epoch 206/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4107 - accuracy: 0.8066 - val_loss: 0.4004 - val_accuracy: 0.8033\n",
      "Epoch 207/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4161 - accuracy: 0.8079 - val_loss: 0.4008 - val_accuracy: 0.8041\n",
      "Epoch 208/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.4122 - accuracy: 0.8070 - val_loss: 0.4009 - val_accuracy: 0.8041\n",
      "Epoch 209/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4096 - accuracy: 0.8125 - val_loss: 0.4006 - val_accuracy: 0.8064\n",
      "Epoch 210/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4101 - accuracy: 0.8109 - val_loss: 0.4002 - val_accuracy: 0.8072\n",
      "Epoch 211/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4125 - accuracy: 0.8088 - val_loss: 0.3999 - val_accuracy: 0.8072\n",
      "Epoch 212/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4122 - accuracy: 0.8100 - val_loss: 0.3994 - val_accuracy: 0.8072\n",
      "Epoch 213/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4167 - accuracy: 0.8084 - val_loss: 0.3980 - val_accuracy: 0.8080\n",
      "Epoch 214/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4086 - accuracy: 0.8116 - val_loss: 0.3968 - val_accuracy: 0.8088\n",
      "Epoch 215/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4067 - accuracy: 0.8105 - val_loss: 0.3958 - val_accuracy: 0.8096\n",
      "Epoch 216/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4070 - accuracy: 0.8102 - val_loss: 0.3948 - val_accuracy: 0.8103\n",
      "Epoch 217/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4093 - accuracy: 0.8129 - val_loss: 0.3942 - val_accuracy: 0.8119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4076 - accuracy: 0.8106 - val_loss: 0.3934 - val_accuracy: 0.8111\n",
      "Epoch 219/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4018 - accuracy: 0.8169 - val_loss: 0.3929 - val_accuracy: 0.8119\n",
      "Epoch 220/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4090 - accuracy: 0.8108 - val_loss: 0.3926 - val_accuracy: 0.8103\n",
      "Epoch 221/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4089 - accuracy: 0.8132 - val_loss: 0.3917 - val_accuracy: 0.8096\n",
      "Epoch 222/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4097 - accuracy: 0.8115 - val_loss: 0.3903 - val_accuracy: 0.8135\n",
      "Epoch 223/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4093 - accuracy: 0.8144 - val_loss: 0.3888 - val_accuracy: 0.8135\n",
      "Epoch 224/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4077 - accuracy: 0.8149 - val_loss: 0.3878 - val_accuracy: 0.8135\n",
      "Epoch 225/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4029 - accuracy: 0.8129 - val_loss: 0.3874 - val_accuracy: 0.8143\n",
      "Epoch 226/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4065 - accuracy: 0.8145 - val_loss: 0.3877 - val_accuracy: 0.8135\n",
      "Epoch 227/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4082 - accuracy: 0.8111 - val_loss: 0.3878 - val_accuracy: 0.8150\n",
      "Epoch 228/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4016 - accuracy: 0.8171 - val_loss: 0.3875 - val_accuracy: 0.8150\n",
      "Epoch 229/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.3865 - val_accuracy: 0.8174\n",
      "Epoch 230/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4066 - accuracy: 0.8108 - val_loss: 0.3855 - val_accuracy: 0.8205\n",
      "Epoch 231/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4067 - accuracy: 0.8127 - val_loss: 0.3849 - val_accuracy: 0.8213\n",
      "Epoch 232/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4066 - accuracy: 0.8128 - val_loss: 0.3838 - val_accuracy: 0.8229\n",
      "Epoch 233/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3985 - accuracy: 0.8159 - val_loss: 0.3830 - val_accuracy: 0.8245\n",
      "Epoch 234/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4016 - accuracy: 0.8187 - val_loss: 0.3822 - val_accuracy: 0.8268\n",
      "Epoch 235/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4027 - accuracy: 0.8144 - val_loss: 0.3819 - val_accuracy: 0.8268\n",
      "Epoch 236/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.4008 - accuracy: 0.8168 - val_loss: 0.3814 - val_accuracy: 0.8284\n",
      "Epoch 237/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4029 - accuracy: 0.8128 - val_loss: 0.3806 - val_accuracy: 0.8292\n",
      "Epoch 238/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4070 - accuracy: 0.8144 - val_loss: 0.3800 - val_accuracy: 0.8284\n",
      "Epoch 239/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3992 - accuracy: 0.8149 - val_loss: 0.3792 - val_accuracy: 0.8284\n",
      "Epoch 240/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.4025 - accuracy: 0.8165 - val_loss: 0.3785 - val_accuracy: 0.8284\n",
      "Epoch 241/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3991 - accuracy: 0.8159 - val_loss: 0.3786 - val_accuracy: 0.8284\n",
      "Epoch 242/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3956 - accuracy: 0.8168 - val_loss: 0.3787 - val_accuracy: 0.8292\n",
      "Epoch 243/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.4011 - accuracy: 0.8157 - val_loss: 0.3788 - val_accuracy: 0.8323\n",
      "Epoch 244/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3957 - accuracy: 0.8180 - val_loss: 0.3787 - val_accuracy: 0.8307\n",
      "Epoch 245/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3985 - accuracy: 0.8203 - val_loss: 0.3784 - val_accuracy: 0.8307\n",
      "Epoch 246/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.4018 - accuracy: 0.8150 - val_loss: 0.3775 - val_accuracy: 0.8315\n",
      "Epoch 247/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.4023 - accuracy: 0.8109 - val_loss: 0.3764 - val_accuracy: 0.8331\n",
      "Epoch 248/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3993 - accuracy: 0.8179 - val_loss: 0.3752 - val_accuracy: 0.8339\n",
      "Epoch 249/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3999 - accuracy: 0.8183 - val_loss: 0.3736 - val_accuracy: 0.8362\n",
      "Epoch 250/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3993 - accuracy: 0.8163 - val_loss: 0.3728 - val_accuracy: 0.8362\n",
      "Epoch 251/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3989 - accuracy: 0.8144 - val_loss: 0.3719 - val_accuracy: 0.8378\n",
      "Epoch 252/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3959 - accuracy: 0.8216 - val_loss: 0.3710 - val_accuracy: 0.8393\n",
      "Epoch 253/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3969 - accuracy: 0.8163 - val_loss: 0.3697 - val_accuracy: 0.8393\n",
      "Epoch 254/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3987 - accuracy: 0.8157 - val_loss: 0.3685 - val_accuracy: 0.8393\n",
      "Epoch 255/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3939 - accuracy: 0.8206 - val_loss: 0.3681 - val_accuracy: 0.8401\n",
      "Epoch 256/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3898 - accuracy: 0.8193 - val_loss: 0.3683 - val_accuracy: 0.8409\n",
      "Epoch 257/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3998 - accuracy: 0.8156 - val_loss: 0.3682 - val_accuracy: 0.8393\n",
      "Epoch 258/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3903 - accuracy: 0.8206 - val_loss: 0.3675 - val_accuracy: 0.8386\n",
      "Epoch 259/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3987 - accuracy: 0.8167 - val_loss: 0.3661 - val_accuracy: 0.8386\n",
      "Epoch 260/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3984 - accuracy: 0.8169 - val_loss: 0.3647 - val_accuracy: 0.8386\n",
      "Epoch 261/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3957 - accuracy: 0.8179 - val_loss: 0.3640 - val_accuracy: 0.8401\n",
      "Epoch 262/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3923 - accuracy: 0.8231 - val_loss: 0.3631 - val_accuracy: 0.8393\n",
      "Epoch 263/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3935 - accuracy: 0.8192 - val_loss: 0.3624 - val_accuracy: 0.8393\n",
      "Epoch 264/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3923 - accuracy: 0.8183 - val_loss: 0.3622 - val_accuracy: 0.8386\n",
      "Epoch 265/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3924 - accuracy: 0.8159 - val_loss: 0.3627 - val_accuracy: 0.8370\n",
      "Epoch 266/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3942 - accuracy: 0.8225 - val_loss: 0.3632 - val_accuracy: 0.8354\n",
      "Epoch 267/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3887 - accuracy: 0.8204 - val_loss: 0.3639 - val_accuracy: 0.8354\n",
      "Epoch 268/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3924 - accuracy: 0.8220 - val_loss: 0.3645 - val_accuracy: 0.8362\n",
      "Epoch 269/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.3890 - accuracy: 0.8216 - val_loss: 0.3647 - val_accuracy: 0.8370\n",
      "Epoch 270/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3847 - accuracy: 0.8242 - val_loss: 0.3647 - val_accuracy: 0.8386\n",
      "Epoch 271/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3885 - accuracy: 0.8234 - val_loss: 0.3642 - val_accuracy: 0.8409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3926 - accuracy: 0.8173 - val_loss: 0.3634 - val_accuracy: 0.8425\n",
      "Epoch 273/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3934 - accuracy: 0.8207 - val_loss: 0.3620 - val_accuracy: 0.8440\n",
      "Epoch 274/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3900 - accuracy: 0.8206 - val_loss: 0.3602 - val_accuracy: 0.8472\n",
      "Epoch 275/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3918 - accuracy: 0.8198 - val_loss: 0.3582 - val_accuracy: 0.8480\n",
      "Epoch 276/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3863 - accuracy: 0.8220 - val_loss: 0.3563 - val_accuracy: 0.8487\n",
      "Epoch 277/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3872 - accuracy: 0.8238 - val_loss: 0.3551 - val_accuracy: 0.8487\n",
      "Epoch 278/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3872 - accuracy: 0.8238 - val_loss: 0.3544 - val_accuracy: 0.8495\n",
      "Epoch 279/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3887 - accuracy: 0.8199 - val_loss: 0.3544 - val_accuracy: 0.8495\n",
      "Epoch 280/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3840 - accuracy: 0.8234 - val_loss: 0.3547 - val_accuracy: 0.8487\n",
      "Epoch 281/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3838 - accuracy: 0.8251 - val_loss: 0.3557 - val_accuracy: 0.8495\n",
      "Epoch 282/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3881 - accuracy: 0.8201 - val_loss: 0.3567 - val_accuracy: 0.8511\n",
      "Epoch 283/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3899 - accuracy: 0.8211 - val_loss: 0.3566 - val_accuracy: 0.8519\n",
      "Epoch 284/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3879 - accuracy: 0.8238 - val_loss: 0.3558 - val_accuracy: 0.8519\n",
      "Epoch 285/800\n",
      "11480/11480 [==============================] - 0s 33us/sample - loss: 0.3859 - accuracy: 0.8209 - val_loss: 0.3539 - val_accuracy: 0.8542\n",
      "Epoch 286/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3894 - accuracy: 0.8219 - val_loss: 0.3521 - val_accuracy: 0.8550\n",
      "Epoch 287/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3852 - accuracy: 0.8227 - val_loss: 0.3507 - val_accuracy: 0.8558\n",
      "Epoch 288/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3835 - accuracy: 0.8224 - val_loss: 0.3497 - val_accuracy: 0.8566\n",
      "Epoch 289/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3775 - accuracy: 0.8261 - val_loss: 0.3491 - val_accuracy: 0.8582\n",
      "Epoch 290/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3871 - accuracy: 0.8246 - val_loss: 0.3480 - val_accuracy: 0.8574\n",
      "Epoch 291/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3816 - accuracy: 0.8277 - val_loss: 0.3472 - val_accuracy: 0.8574\n",
      "Epoch 292/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3825 - accuracy: 0.8244 - val_loss: 0.3469 - val_accuracy: 0.8566\n",
      "Epoch 293/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3842 - accuracy: 0.8221 - val_loss: 0.3474 - val_accuracy: 0.8566\n",
      "Epoch 294/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3824 - accuracy: 0.8242 - val_loss: 0.3479 - val_accuracy: 0.8566\n",
      "Epoch 295/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3855 - accuracy: 0.8217 - val_loss: 0.3484 - val_accuracy: 0.8574\n",
      "Epoch 296/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3799 - accuracy: 0.8235 - val_loss: 0.3488 - val_accuracy: 0.8574\n",
      "Epoch 297/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3843 - accuracy: 0.8252 - val_loss: 0.3481 - val_accuracy: 0.8582\n",
      "Epoch 298/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3832 - accuracy: 0.8249 - val_loss: 0.3474 - val_accuracy: 0.8582\n",
      "Epoch 299/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3804 - accuracy: 0.8252 - val_loss: 0.3462 - val_accuracy: 0.8582\n",
      "Epoch 300/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3838 - accuracy: 0.8233 - val_loss: 0.3454 - val_accuracy: 0.8582\n",
      "Epoch 301/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3791 - accuracy: 0.8244 - val_loss: 0.3449 - val_accuracy: 0.8582\n",
      "Epoch 302/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3789 - accuracy: 0.8263 - val_loss: 0.3448 - val_accuracy: 0.8589\n",
      "Epoch 303/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3827 - accuracy: 0.8255 - val_loss: 0.3443 - val_accuracy: 0.8589\n",
      "Epoch 304/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3798 - accuracy: 0.8269 - val_loss: 0.3436 - val_accuracy: 0.8589\n",
      "Epoch 305/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3783 - accuracy: 0.8248 - val_loss: 0.3429 - val_accuracy: 0.8589\n",
      "Epoch 306/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3768 - accuracy: 0.8272 - val_loss: 0.3426 - val_accuracy: 0.8589\n",
      "Epoch 307/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3791 - accuracy: 0.8276 - val_loss: 0.3416 - val_accuracy: 0.8589\n",
      "Epoch 308/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3748 - accuracy: 0.8307 - val_loss: 0.3408 - val_accuracy: 0.8597\n",
      "Epoch 309/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3769 - accuracy: 0.8258 - val_loss: 0.3404 - val_accuracy: 0.8597\n",
      "Epoch 310/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3774 - accuracy: 0.8248 - val_loss: 0.3401 - val_accuracy: 0.8605\n",
      "Epoch 311/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3730 - accuracy: 0.8294 - val_loss: 0.3396 - val_accuracy: 0.8613\n",
      "Epoch 312/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3758 - accuracy: 0.8259 - val_loss: 0.3390 - val_accuracy: 0.8629\n",
      "Epoch 313/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3776 - accuracy: 0.8278 - val_loss: 0.3390 - val_accuracy: 0.8629\n",
      "Epoch 314/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3733 - accuracy: 0.8287 - val_loss: 0.3387 - val_accuracy: 0.8621\n",
      "Epoch 315/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3775 - accuracy: 0.8250 - val_loss: 0.3380 - val_accuracy: 0.8621\n",
      "Epoch 316/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3768 - accuracy: 0.8294 - val_loss: 0.3370 - val_accuracy: 0.8629\n",
      "Epoch 317/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3751 - accuracy: 0.8269 - val_loss: 0.3357 - val_accuracy: 0.8660\n",
      "Epoch 318/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3773 - accuracy: 0.8259 - val_loss: 0.3348 - val_accuracy: 0.8668\n",
      "Epoch 319/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3725 - accuracy: 0.8269 - val_loss: 0.3335 - val_accuracy: 0.8668\n",
      "Epoch 320/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3751 - accuracy: 0.8274 - val_loss: 0.3319 - val_accuracy: 0.8691\n",
      "Epoch 321/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3722 - accuracy: 0.8321 - val_loss: 0.3305 - val_accuracy: 0.8691\n",
      "Epoch 322/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3736 - accuracy: 0.8302 - val_loss: 0.3301 - val_accuracy: 0.8676\n",
      "Epoch 323/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3753 - accuracy: 0.8305 - val_loss: 0.3303 - val_accuracy: 0.8676\n",
      "Epoch 324/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3724 - accuracy: 0.8282 - val_loss: 0.3302 - val_accuracy: 0.8691\n",
      "Epoch 325/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3722 - accuracy: 0.8281 - val_loss: 0.3304 - val_accuracy: 0.8691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3738 - accuracy: 0.8293 - val_loss: 0.3305 - val_accuracy: 0.8676\n",
      "Epoch 327/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3762 - accuracy: 0.8267 - val_loss: 0.3307 - val_accuracy: 0.8668\n",
      "Epoch 328/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3690 - accuracy: 0.8348 - val_loss: 0.3304 - val_accuracy: 0.8676\n",
      "Epoch 329/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3749 - accuracy: 0.8301 - val_loss: 0.3303 - val_accuracy: 0.8668\n",
      "Epoch 330/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3693 - accuracy: 0.8352 - val_loss: 0.3306 - val_accuracy: 0.8668\n",
      "Epoch 331/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3687 - accuracy: 0.8310 - val_loss: 0.3303 - val_accuracy: 0.8660\n",
      "Epoch 332/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.3724 - accuracy: 0.8275 - val_loss: 0.3293 - val_accuracy: 0.8683\n",
      "Epoch 333/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3677 - accuracy: 0.8310 - val_loss: 0.3281 - val_accuracy: 0.8691\n",
      "Epoch 334/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3681 - accuracy: 0.8336 - val_loss: 0.3267 - val_accuracy: 0.8707\n",
      "Epoch 335/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3643 - accuracy: 0.8335 - val_loss: 0.3252 - val_accuracy: 0.8715\n",
      "Epoch 336/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.3679 - accuracy: 0.8315 - val_loss: 0.3245 - val_accuracy: 0.8723\n",
      "Epoch 337/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3701 - accuracy: 0.8341 - val_loss: 0.3245 - val_accuracy: 0.8723\n",
      "Epoch 338/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3732 - accuracy: 0.8284 - val_loss: 0.3252 - val_accuracy: 0.8707\n",
      "Epoch 339/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3694 - accuracy: 0.8332 - val_loss: 0.3262 - val_accuracy: 0.8707\n",
      "Epoch 340/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3676 - accuracy: 0.8313 - val_loss: 0.3266 - val_accuracy: 0.8715\n",
      "Epoch 341/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3690 - accuracy: 0.8343 - val_loss: 0.3265 - val_accuracy: 0.8715\n",
      "Epoch 342/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3605 - accuracy: 0.8425 - val_loss: 0.3267 - val_accuracy: 0.8723\n",
      "Epoch 343/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3705 - accuracy: 0.8313 - val_loss: 0.3264 - val_accuracy: 0.8730\n",
      "Epoch 344/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3670 - accuracy: 0.8296 - val_loss: 0.3259 - val_accuracy: 0.8730\n",
      "Epoch 345/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.3695 - accuracy: 0.8321 - val_loss: 0.3251 - val_accuracy: 0.8715\n",
      "Epoch 346/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3640 - accuracy: 0.8327 - val_loss: 0.3233 - val_accuracy: 0.8723\n",
      "Epoch 347/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3666 - accuracy: 0.8340 - val_loss: 0.3210 - val_accuracy: 0.8723\n",
      "Epoch 348/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3680 - accuracy: 0.8339 - val_loss: 0.3187 - val_accuracy: 0.8723\n",
      "Epoch 349/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3644 - accuracy: 0.8338 - val_loss: 0.3171 - val_accuracy: 0.8723\n",
      "Epoch 350/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3629 - accuracy: 0.8360 - val_loss: 0.3158 - val_accuracy: 0.8738\n",
      "Epoch 351/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3654 - accuracy: 0.8347 - val_loss: 0.3156 - val_accuracy: 0.8754\n",
      "Epoch 352/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3624 - accuracy: 0.8367 - val_loss: 0.3169 - val_accuracy: 0.8746\n",
      "Epoch 353/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3694 - accuracy: 0.8327 - val_loss: 0.3184 - val_accuracy: 0.8723\n",
      "Epoch 354/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3652 - accuracy: 0.8399 - val_loss: 0.3192 - val_accuracy: 0.8723\n",
      "Epoch 355/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3709 - accuracy: 0.8321 - val_loss: 0.3192 - val_accuracy: 0.8730\n",
      "Epoch 356/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.3631 - accuracy: 0.8358 - val_loss: 0.3185 - val_accuracy: 0.8730\n",
      "Epoch 357/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3666 - accuracy: 0.8328 - val_loss: 0.3175 - val_accuracy: 0.8754\n",
      "Epoch 358/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3639 - accuracy: 0.8304 - val_loss: 0.3156 - val_accuracy: 0.8785\n",
      "Epoch 359/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3597 - accuracy: 0.8384 - val_loss: 0.3141 - val_accuracy: 0.8793\n",
      "Epoch 360/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3626 - accuracy: 0.8344 - val_loss: 0.3124 - val_accuracy: 0.8793\n",
      "Epoch 361/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3614 - accuracy: 0.8348 - val_loss: 0.3114 - val_accuracy: 0.8793\n",
      "Epoch 362/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3612 - accuracy: 0.8378 - val_loss: 0.3102 - val_accuracy: 0.8785\n",
      "Epoch 363/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3629 - accuracy: 0.8357 - val_loss: 0.3097 - val_accuracy: 0.8793\n",
      "Epoch 364/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3588 - accuracy: 0.8360 - val_loss: 0.3098 - val_accuracy: 0.8785\n",
      "Epoch 365/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3569 - accuracy: 0.8382 - val_loss: 0.3104 - val_accuracy: 0.8762\n",
      "Epoch 366/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3622 - accuracy: 0.8383 - val_loss: 0.3114 - val_accuracy: 0.8746\n",
      "Epoch 367/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3598 - accuracy: 0.8387 - val_loss: 0.3124 - val_accuracy: 0.8738\n",
      "Epoch 368/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3577 - accuracy: 0.8368 - val_loss: 0.3138 - val_accuracy: 0.8738\n",
      "Epoch 369/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3636 - accuracy: 0.8349 - val_loss: 0.3147 - val_accuracy: 0.8723\n",
      "Epoch 370/800\n",
      "11480/11480 [==============================] - 0s 32us/sample - loss: 0.3573 - accuracy: 0.8356 - val_loss: 0.3144 - val_accuracy: 0.8723\n",
      "Epoch 371/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3571 - accuracy: 0.8353 - val_loss: 0.3131 - val_accuracy: 0.8746\n",
      "Epoch 372/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3607 - accuracy: 0.8382 - val_loss: 0.3106 - val_accuracy: 0.8746\n",
      "Epoch 373/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3551 - accuracy: 0.8364 - val_loss: 0.3076 - val_accuracy: 0.8738\n",
      "Epoch 374/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3557 - accuracy: 0.8367 - val_loss: 0.3044 - val_accuracy: 0.8762\n",
      "Epoch 375/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3499 - accuracy: 0.8443 - val_loss: 0.3019 - val_accuracy: 0.8770\n",
      "Epoch 376/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3577 - accuracy: 0.8396 - val_loss: 0.3004 - val_accuracy: 0.8777\n",
      "Epoch 377/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3559 - accuracy: 0.8377 - val_loss: 0.3004 - val_accuracy: 0.8785\n",
      "Epoch 378/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3564 - accuracy: 0.8375 - val_loss: 0.3011 - val_accuracy: 0.8793\n",
      "Epoch 379/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3554 - accuracy: 0.8409 - val_loss: 0.3027 - val_accuracy: 0.8793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3544 - accuracy: 0.8388 - val_loss: 0.3044 - val_accuracy: 0.8777\n",
      "Epoch 381/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3551 - accuracy: 0.8428 - val_loss: 0.3058 - val_accuracy: 0.8777\n",
      "Epoch 382/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3614 - accuracy: 0.8349 - val_loss: 0.3063 - val_accuracy: 0.8770\n",
      "Epoch 383/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3519 - accuracy: 0.8428 - val_loss: 0.3068 - val_accuracy: 0.8754\n",
      "Epoch 384/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3571 - accuracy: 0.8411 - val_loss: 0.3064 - val_accuracy: 0.8754\n",
      "Epoch 385/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3603 - accuracy: 0.8362 - val_loss: 0.3053 - val_accuracy: 0.8762\n",
      "Epoch 386/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3572 - accuracy: 0.8353 - val_loss: 0.3040 - val_accuracy: 0.8770\n",
      "Epoch 387/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3510 - accuracy: 0.8419 - val_loss: 0.3023 - val_accuracy: 0.8777\n",
      "Epoch 388/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3517 - accuracy: 0.8393 - val_loss: 0.3012 - val_accuracy: 0.8777\n",
      "Epoch 389/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3571 - accuracy: 0.8400 - val_loss: 0.2992 - val_accuracy: 0.8801\n",
      "Epoch 390/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3547 - accuracy: 0.8382 - val_loss: 0.2974 - val_accuracy: 0.8809\n",
      "Epoch 391/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3477 - accuracy: 0.8420 - val_loss: 0.2959 - val_accuracy: 0.8848\n",
      "Epoch 392/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3490 - accuracy: 0.8393 - val_loss: 0.2949 - val_accuracy: 0.8840\n",
      "Epoch 393/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3561 - accuracy: 0.8387 - val_loss: 0.2946 - val_accuracy: 0.8848\n",
      "Epoch 394/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3550 - accuracy: 0.8401 - val_loss: 0.2952 - val_accuracy: 0.8840\n",
      "Epoch 395/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3492 - accuracy: 0.8443 - val_loss: 0.2963 - val_accuracy: 0.8840\n",
      "Epoch 396/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3530 - accuracy: 0.8414 - val_loss: 0.2969 - val_accuracy: 0.8848\n",
      "Epoch 397/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3501 - accuracy: 0.8382 - val_loss: 0.2982 - val_accuracy: 0.8840\n",
      "Epoch 398/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3505 - accuracy: 0.8384 - val_loss: 0.2993 - val_accuracy: 0.8824\n",
      "Epoch 399/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3487 - accuracy: 0.8394 - val_loss: 0.2993 - val_accuracy: 0.8824\n",
      "Epoch 400/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3483 - accuracy: 0.8438 - val_loss: 0.2980 - val_accuracy: 0.8817\n",
      "Epoch 401/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3500 - accuracy: 0.8426 - val_loss: 0.2952 - val_accuracy: 0.8824\n",
      "Epoch 402/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3526 - accuracy: 0.8396 - val_loss: 0.2926 - val_accuracy: 0.8832\n",
      "Epoch 403/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3469 - accuracy: 0.8436 - val_loss: 0.2894 - val_accuracy: 0.8848\n",
      "Epoch 404/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3498 - accuracy: 0.8432 - val_loss: 0.2865 - val_accuracy: 0.8856\n",
      "Epoch 405/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3457 - accuracy: 0.8455 - val_loss: 0.2853 - val_accuracy: 0.8871\n",
      "Epoch 406/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3509 - accuracy: 0.8420 - val_loss: 0.2851 - val_accuracy: 0.8879\n",
      "Epoch 407/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3475 - accuracy: 0.8427 - val_loss: 0.2861 - val_accuracy: 0.8879\n",
      "Epoch 408/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3386 - accuracy: 0.8497 - val_loss: 0.2899 - val_accuracy: 0.8871\n",
      "Epoch 409/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3447 - accuracy: 0.8422 - val_loss: 0.2934 - val_accuracy: 0.8856\n",
      "Epoch 410/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3420 - accuracy: 0.8475 - val_loss: 0.2957 - val_accuracy: 0.8848\n",
      "Epoch 411/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3424 - accuracy: 0.8497 - val_loss: 0.2977 - val_accuracy: 0.8809\n",
      "Epoch 412/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3455 - accuracy: 0.8442 - val_loss: 0.2977 - val_accuracy: 0.8817\n",
      "Epoch 413/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3462 - accuracy: 0.8459 - val_loss: 0.2965 - val_accuracy: 0.8848\n",
      "Epoch 414/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3402 - accuracy: 0.8454 - val_loss: 0.2946 - val_accuracy: 0.8871\n",
      "Epoch 415/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3426 - accuracy: 0.8443 - val_loss: 0.2915 - val_accuracy: 0.8871\n",
      "Epoch 416/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3437 - accuracy: 0.8459 - val_loss: 0.2878 - val_accuracy: 0.8895\n",
      "Epoch 417/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3453 - accuracy: 0.8469 - val_loss: 0.2841 - val_accuracy: 0.8887\n",
      "Epoch 418/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3419 - accuracy: 0.8461 - val_loss: 0.2818 - val_accuracy: 0.8879\n",
      "Epoch 419/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3439 - accuracy: 0.8456 - val_loss: 0.2807 - val_accuracy: 0.8879\n",
      "Epoch 420/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3418 - accuracy: 0.8477 - val_loss: 0.2812 - val_accuracy: 0.8887\n",
      "Epoch 421/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3443 - accuracy: 0.8456 - val_loss: 0.2828 - val_accuracy: 0.8871\n",
      "Epoch 422/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3400 - accuracy: 0.8472 - val_loss: 0.2852 - val_accuracy: 0.8871\n",
      "Epoch 423/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3414 - accuracy: 0.8474 - val_loss: 0.2880 - val_accuracy: 0.8848\n",
      "Epoch 424/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3442 - accuracy: 0.8466 - val_loss: 0.2899 - val_accuracy: 0.8848\n",
      "Epoch 425/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3392 - accuracy: 0.8478 - val_loss: 0.2904 - val_accuracy: 0.8856\n",
      "Epoch 426/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3407 - accuracy: 0.8449 - val_loss: 0.2898 - val_accuracy: 0.8856\n",
      "Epoch 427/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3415 - accuracy: 0.8476 - val_loss: 0.2880 - val_accuracy: 0.8856\n",
      "Epoch 428/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3401 - accuracy: 0.8450 - val_loss: 0.2855 - val_accuracy: 0.8879\n",
      "Epoch 429/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3389 - accuracy: 0.8449 - val_loss: 0.2828 - val_accuracy: 0.8895\n",
      "Epoch 430/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3383 - accuracy: 0.8503 - val_loss: 0.2801 - val_accuracy: 0.8918\n",
      "Epoch 431/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3417 - accuracy: 0.8470 - val_loss: 0.2784 - val_accuracy: 0.8918\n",
      "Epoch 432/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3394 - accuracy: 0.8490 - val_loss: 0.2768 - val_accuracy: 0.8926\n",
      "Epoch 433/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3427 - accuracy: 0.8450 - val_loss: 0.2772 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3369 - accuracy: 0.8453 - val_loss: 0.2776 - val_accuracy: 0.8934\n",
      "Epoch 435/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3420 - accuracy: 0.8453 - val_loss: 0.2780 - val_accuracy: 0.8942\n",
      "Epoch 436/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3380 - accuracy: 0.8477 - val_loss: 0.2785 - val_accuracy: 0.8942\n",
      "Epoch 437/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3368 - accuracy: 0.8470 - val_loss: 0.2784 - val_accuracy: 0.8926\n",
      "Epoch 438/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3376 - accuracy: 0.8483 - val_loss: 0.2782 - val_accuracy: 0.8918\n",
      "Epoch 439/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3411 - accuracy: 0.8471 - val_loss: 0.2785 - val_accuracy: 0.8918\n",
      "Epoch 440/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3391 - accuracy: 0.8476 - val_loss: 0.2776 - val_accuracy: 0.8926\n",
      "Epoch 441/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3325 - accuracy: 0.8493 - val_loss: 0.2760 - val_accuracy: 0.8926\n",
      "Epoch 442/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3380 - accuracy: 0.8448 - val_loss: 0.2747 - val_accuracy: 0.8926\n",
      "Epoch 443/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3360 - accuracy: 0.8479 - val_loss: 0.2738 - val_accuracy: 0.8934\n",
      "Epoch 444/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3369 - accuracy: 0.8506 - val_loss: 0.2736 - val_accuracy: 0.8942\n",
      "Epoch 445/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3323 - accuracy: 0.8497 - val_loss: 0.2730 - val_accuracy: 0.8942\n",
      "Epoch 446/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3327 - accuracy: 0.8530 - val_loss: 0.2720 - val_accuracy: 0.8942\n",
      "Epoch 447/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3351 - accuracy: 0.8483 - val_loss: 0.2710 - val_accuracy: 0.8950\n",
      "Epoch 448/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3379 - accuracy: 0.8472 - val_loss: 0.2700 - val_accuracy: 0.8950\n",
      "Epoch 449/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3342 - accuracy: 0.8498 - val_loss: 0.2706 - val_accuracy: 0.8942\n",
      "Epoch 450/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3324 - accuracy: 0.8528 - val_loss: 0.2706 - val_accuracy: 0.8942\n",
      "Epoch 451/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3356 - accuracy: 0.8492 - val_loss: 0.2700 - val_accuracy: 0.8950\n",
      "Epoch 452/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3318 - accuracy: 0.8524 - val_loss: 0.2698 - val_accuracy: 0.8958\n",
      "Epoch 453/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3343 - accuracy: 0.8527 - val_loss: 0.2705 - val_accuracy: 0.8958\n",
      "Epoch 454/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3355 - accuracy: 0.8496 - val_loss: 0.2711 - val_accuracy: 0.8942\n",
      "Epoch 455/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3344 - accuracy: 0.8468 - val_loss: 0.2718 - val_accuracy: 0.8942\n",
      "Epoch 456/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3301 - accuracy: 0.8517 - val_loss: 0.2726 - val_accuracy: 0.8942\n",
      "Epoch 457/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3297 - accuracy: 0.8535 - val_loss: 0.2735 - val_accuracy: 0.8950\n",
      "Epoch 458/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3266 - accuracy: 0.8533 - val_loss: 0.2744 - val_accuracy: 0.8950\n",
      "Epoch 459/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3330 - accuracy: 0.8500 - val_loss: 0.2741 - val_accuracy: 0.8958\n",
      "Epoch 460/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3297 - accuracy: 0.8542 - val_loss: 0.2725 - val_accuracy: 0.8966\n",
      "Epoch 461/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3282 - accuracy: 0.8544 - val_loss: 0.2701 - val_accuracy: 0.8966\n",
      "Epoch 462/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3269 - accuracy: 0.8528 - val_loss: 0.2677 - val_accuracy: 0.8966\n",
      "Epoch 463/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3258 - accuracy: 0.8558 - val_loss: 0.2649 - val_accuracy: 0.8981\n",
      "Epoch 464/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3311 - accuracy: 0.8551 - val_loss: 0.2631 - val_accuracy: 0.8997\n",
      "Epoch 465/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3282 - accuracy: 0.8521 - val_loss: 0.2628 - val_accuracy: 0.8997\n",
      "Epoch 466/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3293 - accuracy: 0.8527 - val_loss: 0.2627 - val_accuracy: 0.8997\n",
      "Epoch 467/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3239 - accuracy: 0.8550 - val_loss: 0.2632 - val_accuracy: 0.8997\n",
      "Epoch 468/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3274 - accuracy: 0.8550 - val_loss: 0.2639 - val_accuracy: 0.8997\n",
      "Epoch 469/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3291 - accuracy: 0.8513 - val_loss: 0.2639 - val_accuracy: 0.8989\n",
      "Epoch 470/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3316 - accuracy: 0.8511 - val_loss: 0.2640 - val_accuracy: 0.8981\n",
      "Epoch 471/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3257 - accuracy: 0.8537 - val_loss: 0.2634 - val_accuracy: 0.8989\n",
      "Epoch 472/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3263 - accuracy: 0.8554 - val_loss: 0.2621 - val_accuracy: 0.8997\n",
      "Epoch 473/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3329 - accuracy: 0.8502 - val_loss: 0.2618 - val_accuracy: 0.8997\n",
      "Epoch 474/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3249 - accuracy: 0.8572 - val_loss: 0.2606 - val_accuracy: 0.8989\n",
      "Epoch 475/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3272 - accuracy: 0.8539 - val_loss: 0.2602 - val_accuracy: 0.8997\n",
      "Epoch 476/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3230 - accuracy: 0.8554 - val_loss: 0.2605 - val_accuracy: 0.8989\n",
      "Epoch 477/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3276 - accuracy: 0.8558 - val_loss: 0.2611 - val_accuracy: 0.9005\n",
      "Epoch 478/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3290 - accuracy: 0.8531 - val_loss: 0.2618 - val_accuracy: 0.8997\n",
      "Epoch 479/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3271 - accuracy: 0.8536 - val_loss: 0.2629 - val_accuracy: 0.9005\n",
      "Epoch 480/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3300 - accuracy: 0.8505 - val_loss: 0.2637 - val_accuracy: 0.9013\n",
      "Epoch 481/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3242 - accuracy: 0.8527 - val_loss: 0.2640 - val_accuracy: 0.9013\n",
      "Epoch 482/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3253 - accuracy: 0.8555 - val_loss: 0.2640 - val_accuracy: 0.9020\n",
      "Epoch 483/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3224 - accuracy: 0.8530 - val_loss: 0.2635 - val_accuracy: 0.9020\n",
      "Epoch 484/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3224 - accuracy: 0.8554 - val_loss: 0.2622 - val_accuracy: 0.9013\n",
      "Epoch 485/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3237 - accuracy: 0.8528 - val_loss: 0.2617 - val_accuracy: 0.9028\n",
      "Epoch 486/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3254 - accuracy: 0.8574 - val_loss: 0.2610 - val_accuracy: 0.9036\n",
      "Epoch 487/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3229 - accuracy: 0.8574 - val_loss: 0.2596 - val_accuracy: 0.9020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3246 - accuracy: 0.8577 - val_loss: 0.2578 - val_accuracy: 0.9020\n",
      "Epoch 489/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3267 - accuracy: 0.8506 - val_loss: 0.2558 - val_accuracy: 0.9044\n",
      "Epoch 490/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3260 - accuracy: 0.8525 - val_loss: 0.2538 - val_accuracy: 0.9060\n",
      "Epoch 491/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3223 - accuracy: 0.8573 - val_loss: 0.2531 - val_accuracy: 0.9060\n",
      "Epoch 492/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3273 - accuracy: 0.8528 - val_loss: 0.2534 - val_accuracy: 0.9052\n",
      "Epoch 493/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3268 - accuracy: 0.8555 - val_loss: 0.2536 - val_accuracy: 0.9052\n",
      "Epoch 494/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3237 - accuracy: 0.8563 - val_loss: 0.2549 - val_accuracy: 0.9036\n",
      "Epoch 495/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3250 - accuracy: 0.8531 - val_loss: 0.2564 - val_accuracy: 0.9020\n",
      "Epoch 496/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3213 - accuracy: 0.8568 - val_loss: 0.2575 - val_accuracy: 0.9013\n",
      "Epoch 497/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3201 - accuracy: 0.8559 - val_loss: 0.2588 - val_accuracy: 0.8989\n",
      "Epoch 498/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3231 - accuracy: 0.8587 - val_loss: 0.2595 - val_accuracy: 0.9005\n",
      "Epoch 499/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3203 - accuracy: 0.8578 - val_loss: 0.2596 - val_accuracy: 0.8997\n",
      "Epoch 500/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3204 - accuracy: 0.8568 - val_loss: 0.2588 - val_accuracy: 0.8997\n",
      "Epoch 501/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3227 - accuracy: 0.8545 - val_loss: 0.2576 - val_accuracy: 0.8997\n",
      "Epoch 502/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3211 - accuracy: 0.8550 - val_loss: 0.2561 - val_accuracy: 0.9028\n",
      "Epoch 503/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3241 - accuracy: 0.8560 - val_loss: 0.2542 - val_accuracy: 0.9044\n",
      "Epoch 504/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3253 - accuracy: 0.8540 - val_loss: 0.2523 - val_accuracy: 0.9044\n",
      "Epoch 505/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3246 - accuracy: 0.8545 - val_loss: 0.2513 - val_accuracy: 0.9036\n",
      "Epoch 506/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3228 - accuracy: 0.8563 - val_loss: 0.2498 - val_accuracy: 0.9052\n",
      "Epoch 507/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3221 - accuracy: 0.8605 - val_loss: 0.2494 - val_accuracy: 0.9067\n",
      "Epoch 508/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3198 - accuracy: 0.8603 - val_loss: 0.2503 - val_accuracy: 0.9067\n",
      "Epoch 509/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3182 - accuracy: 0.8584 - val_loss: 0.2515 - val_accuracy: 0.9067\n",
      "Epoch 510/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3206 - accuracy: 0.8561 - val_loss: 0.2529 - val_accuracy: 0.9036\n",
      "Epoch 511/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3192 - accuracy: 0.8552 - val_loss: 0.2532 - val_accuracy: 0.9013\n",
      "Epoch 512/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3146 - accuracy: 0.8580 - val_loss: 0.2537 - val_accuracy: 0.9005\n",
      "Epoch 513/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3159 - accuracy: 0.8598 - val_loss: 0.2541 - val_accuracy: 0.8997\n",
      "Epoch 514/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3186 - accuracy: 0.8587 - val_loss: 0.2538 - val_accuracy: 0.9005\n",
      "Epoch 515/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3143 - accuracy: 0.8583 - val_loss: 0.2529 - val_accuracy: 0.9036\n",
      "Epoch 516/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3130 - accuracy: 0.8613 - val_loss: 0.2516 - val_accuracy: 0.9044\n",
      "Epoch 517/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3158 - accuracy: 0.8598 - val_loss: 0.2509 - val_accuracy: 0.9060\n",
      "Epoch 518/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3143 - accuracy: 0.8599 - val_loss: 0.2496 - val_accuracy: 0.9067\n",
      "Epoch 519/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3188 - accuracy: 0.8581 - val_loss: 0.2490 - val_accuracy: 0.9083\n",
      "Epoch 520/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3155 - accuracy: 0.8583 - val_loss: 0.2486 - val_accuracy: 0.9091\n",
      "Epoch 521/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3171 - accuracy: 0.8594 - val_loss: 0.2481 - val_accuracy: 0.9091\n",
      "Epoch 522/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3127 - accuracy: 0.8627 - val_loss: 0.2476 - val_accuracy: 0.9099\n",
      "Epoch 523/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3151 - accuracy: 0.8618 - val_loss: 0.2469 - val_accuracy: 0.9107\n",
      "Epoch 524/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3143 - accuracy: 0.8599 - val_loss: 0.2479 - val_accuracy: 0.9099\n",
      "Epoch 525/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3159 - accuracy: 0.8633 - val_loss: 0.2487 - val_accuracy: 0.9099\n",
      "Epoch 526/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3141 - accuracy: 0.8618 - val_loss: 0.2492 - val_accuracy: 0.9091\n",
      "Epoch 527/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3168 - accuracy: 0.8579 - val_loss: 0.2492 - val_accuracy: 0.9091\n",
      "Epoch 528/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3184 - accuracy: 0.8605 - val_loss: 0.2496 - val_accuracy: 0.9091\n",
      "Epoch 529/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3172 - accuracy: 0.8571 - val_loss: 0.2491 - val_accuracy: 0.9099\n",
      "Epoch 530/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3130 - accuracy: 0.8608 - val_loss: 0.2481 - val_accuracy: 0.9099\n",
      "Epoch 531/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3148 - accuracy: 0.8582 - val_loss: 0.2454 - val_accuracy: 0.9099\n",
      "Epoch 532/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3136 - accuracy: 0.8631 - val_loss: 0.2419 - val_accuracy: 0.9114\n",
      "Epoch 533/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3169 - accuracy: 0.8610 - val_loss: 0.2400 - val_accuracy: 0.9138\n",
      "Epoch 534/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3153 - accuracy: 0.8585 - val_loss: 0.2387 - val_accuracy: 0.9122\n",
      "Epoch 535/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3155 - accuracy: 0.8591 - val_loss: 0.2389 - val_accuracy: 0.9122\n",
      "Epoch 536/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.3137 - accuracy: 0.8604 - val_loss: 0.2397 - val_accuracy: 0.9138\n",
      "Epoch 537/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3135 - accuracy: 0.8606 - val_loss: 0.2414 - val_accuracy: 0.9138\n",
      "Epoch 538/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3116 - accuracy: 0.8611 - val_loss: 0.2432 - val_accuracy: 0.9138\n",
      "Epoch 539/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3156 - accuracy: 0.8600 - val_loss: 0.2437 - val_accuracy: 0.9146\n",
      "Epoch 540/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3090 - accuracy: 0.8608 - val_loss: 0.2437 - val_accuracy: 0.9138\n",
      "Epoch 541/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3134 - accuracy: 0.8601 - val_loss: 0.2426 - val_accuracy: 0.9154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 542/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3107 - accuracy: 0.8605 - val_loss: 0.2402 - val_accuracy: 0.9154\n",
      "Epoch 543/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3079 - accuracy: 0.8629 - val_loss: 0.2379 - val_accuracy: 0.9161\n",
      "Epoch 544/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3085 - accuracy: 0.8640 - val_loss: 0.2369 - val_accuracy: 0.9177\n",
      "Epoch 545/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3066 - accuracy: 0.8649 - val_loss: 0.2360 - val_accuracy: 0.9177\n",
      "Epoch 546/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3134 - accuracy: 0.8595 - val_loss: 0.2354 - val_accuracy: 0.9154\n",
      "Epoch 547/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3085 - accuracy: 0.8642 - val_loss: 0.2348 - val_accuracy: 0.9154\n",
      "Epoch 548/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3081 - accuracy: 0.8611 - val_loss: 0.2338 - val_accuracy: 0.9154\n",
      "Epoch 549/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3147 - accuracy: 0.8635 - val_loss: 0.2341 - val_accuracy: 0.9154\n",
      "Epoch 550/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3106 - accuracy: 0.8598 - val_loss: 0.2341 - val_accuracy: 0.9161\n",
      "Epoch 551/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3088 - accuracy: 0.8602 - val_loss: 0.2341 - val_accuracy: 0.9169\n",
      "Epoch 552/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3083 - accuracy: 0.8638 - val_loss: 0.2351 - val_accuracy: 0.9177\n",
      "Epoch 553/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3077 - accuracy: 0.8687 - val_loss: 0.2367 - val_accuracy: 0.9161\n",
      "Epoch 554/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3120 - accuracy: 0.8627 - val_loss: 0.2390 - val_accuracy: 0.9161\n",
      "Epoch 555/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3112 - accuracy: 0.8624 - val_loss: 0.2399 - val_accuracy: 0.9138\n",
      "Epoch 556/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3051 - accuracy: 0.8652 - val_loss: 0.2394 - val_accuracy: 0.9138\n",
      "Epoch 557/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3074 - accuracy: 0.8635 - val_loss: 0.2385 - val_accuracy: 0.9138\n",
      "Epoch 558/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3090 - accuracy: 0.8618 - val_loss: 0.2372 - val_accuracy: 0.9154\n",
      "Epoch 559/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3148 - accuracy: 0.8583 - val_loss: 0.2358 - val_accuracy: 0.9146\n",
      "Epoch 560/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3075 - accuracy: 0.8629 - val_loss: 0.2339 - val_accuracy: 0.9177\n",
      "Epoch 561/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3093 - accuracy: 0.8625 - val_loss: 0.2327 - val_accuracy: 0.9193\n",
      "Epoch 562/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3008 - accuracy: 0.8661 - val_loss: 0.2323 - val_accuracy: 0.9208\n",
      "Epoch 563/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3014 - accuracy: 0.8681 - val_loss: 0.2322 - val_accuracy: 0.9216\n",
      "Epoch 564/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3062 - accuracy: 0.8642 - val_loss: 0.2325 - val_accuracy: 0.9201\n",
      "Epoch 565/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3035 - accuracy: 0.8644 - val_loss: 0.2328 - val_accuracy: 0.9193\n",
      "Epoch 566/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2971 - accuracy: 0.8691 - val_loss: 0.2328 - val_accuracy: 0.9193\n",
      "Epoch 567/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3078 - accuracy: 0.8650 - val_loss: 0.2318 - val_accuracy: 0.9201\n",
      "Epoch 568/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2997 - accuracy: 0.8675 - val_loss: 0.2319 - val_accuracy: 0.9201\n",
      "Epoch 569/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3085 - accuracy: 0.8637 - val_loss: 0.2332 - val_accuracy: 0.9193\n",
      "Epoch 570/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3055 - accuracy: 0.8645 - val_loss: 0.2335 - val_accuracy: 0.9185\n",
      "Epoch 571/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3061 - accuracy: 0.8625 - val_loss: 0.2324 - val_accuracy: 0.9185\n",
      "Epoch 572/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3056 - accuracy: 0.8640 - val_loss: 0.2315 - val_accuracy: 0.9201\n",
      "Epoch 573/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3063 - accuracy: 0.8632 - val_loss: 0.2312 - val_accuracy: 0.9208\n",
      "Epoch 574/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3027 - accuracy: 0.8683 - val_loss: 0.2320 - val_accuracy: 0.9201\n",
      "Epoch 575/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3053 - accuracy: 0.8639 - val_loss: 0.2320 - val_accuracy: 0.9208\n",
      "Epoch 576/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3005 - accuracy: 0.8645 - val_loss: 0.2319 - val_accuracy: 0.9201\n",
      "Epoch 577/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3004 - accuracy: 0.8682 - val_loss: 0.2324 - val_accuracy: 0.9201\n",
      "Epoch 578/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3045 - accuracy: 0.8650 - val_loss: 0.2325 - val_accuracy: 0.9201\n",
      "Epoch 579/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3023 - accuracy: 0.8646 - val_loss: 0.2325 - val_accuracy: 0.9208\n",
      "Epoch 580/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2976 - accuracy: 0.8703 - val_loss: 0.2320 - val_accuracy: 0.9216\n",
      "Epoch 581/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3014 - accuracy: 0.8689 - val_loss: 0.2305 - val_accuracy: 0.9216\n",
      "Epoch 582/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2981 - accuracy: 0.8668 - val_loss: 0.2281 - val_accuracy: 0.9224\n",
      "Epoch 583/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2976 - accuracy: 0.8699 - val_loss: 0.2250 - val_accuracy: 0.9240\n",
      "Epoch 584/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3046 - accuracy: 0.8687 - val_loss: 0.2227 - val_accuracy: 0.9248\n",
      "Epoch 585/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3052 - accuracy: 0.8645 - val_loss: 0.2227 - val_accuracy: 0.9255\n",
      "Epoch 586/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3032 - accuracy: 0.8616 - val_loss: 0.2237 - val_accuracy: 0.9255\n",
      "Epoch 587/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.3000 - accuracy: 0.8652 - val_loss: 0.2251 - val_accuracy: 0.9240\n",
      "Epoch 588/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3027 - accuracy: 0.8661 - val_loss: 0.2261 - val_accuracy: 0.9240\n",
      "Epoch 589/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2979 - accuracy: 0.8671 - val_loss: 0.2278 - val_accuracy: 0.9224\n",
      "Epoch 590/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3038 - accuracy: 0.8632 - val_loss: 0.2289 - val_accuracy: 0.9216\n",
      "Epoch 591/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2998 - accuracy: 0.8677 - val_loss: 0.2289 - val_accuracy: 0.9216\n",
      "Epoch 592/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3046 - accuracy: 0.8650 - val_loss: 0.2285 - val_accuracy: 0.9232\n",
      "Epoch 593/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2990 - accuracy: 0.8651 - val_loss: 0.2273 - val_accuracy: 0.9255\n",
      "Epoch 594/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2978 - accuracy: 0.8669 - val_loss: 0.2263 - val_accuracy: 0.9263\n",
      "Epoch 595/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2978 - accuracy: 0.8704 - val_loss: 0.2251 - val_accuracy: 0.9271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 596/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.3010 - accuracy: 0.8693 - val_loss: 0.2243 - val_accuracy: 0.9271\n",
      "Epoch 597/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2957 - accuracy: 0.8692 - val_loss: 0.2240 - val_accuracy: 0.9287\n",
      "Epoch 598/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2957 - accuracy: 0.8698 - val_loss: 0.2230 - val_accuracy: 0.9318\n",
      "Epoch 599/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3018 - accuracy: 0.8693 - val_loss: 0.2210 - val_accuracy: 0.9326\n",
      "Epoch 600/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2926 - accuracy: 0.8712 - val_loss: 0.2192 - val_accuracy: 0.9326\n",
      "Epoch 601/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2967 - accuracy: 0.8700 - val_loss: 0.2178 - val_accuracy: 0.9326\n",
      "Epoch 602/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3021 - accuracy: 0.8648 - val_loss: 0.2177 - val_accuracy: 0.9334\n",
      "Epoch 603/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2936 - accuracy: 0.8723 - val_loss: 0.2188 - val_accuracy: 0.9318\n",
      "Epoch 604/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2984 - accuracy: 0.8666 - val_loss: 0.2195 - val_accuracy: 0.9310\n",
      "Epoch 605/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2955 - accuracy: 0.8691 - val_loss: 0.2192 - val_accuracy: 0.9303\n",
      "Epoch 606/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.3000 - accuracy: 0.8683 - val_loss: 0.2193 - val_accuracy: 0.9303\n",
      "Epoch 607/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2913 - accuracy: 0.8696 - val_loss: 0.2191 - val_accuracy: 0.9310\n",
      "Epoch 608/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2981 - accuracy: 0.8682 - val_loss: 0.2184 - val_accuracy: 0.9310\n",
      "Epoch 609/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2947 - accuracy: 0.8723 - val_loss: 0.2174 - val_accuracy: 0.9310\n",
      "Epoch 610/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2955 - accuracy: 0.8699 - val_loss: 0.2174 - val_accuracy: 0.9310\n",
      "Epoch 611/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.2966 - accuracy: 0.8691 - val_loss: 0.2173 - val_accuracy: 0.9303\n",
      "Epoch 612/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2954 - accuracy: 0.8679 - val_loss: 0.2168 - val_accuracy: 0.9310\n",
      "Epoch 613/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.2938 - accuracy: 0.8699 - val_loss: 0.2162 - val_accuracy: 0.9303\n",
      "Epoch 614/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.2911 - accuracy: 0.8762 - val_loss: 0.2156 - val_accuracy: 0.9295\n",
      "Epoch 615/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2975 - accuracy: 0.8699 - val_loss: 0.2160 - val_accuracy: 0.9310\n",
      "Epoch 616/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2956 - accuracy: 0.8706 - val_loss: 0.2164 - val_accuracy: 0.9303\n",
      "Epoch 617/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2896 - accuracy: 0.8715 - val_loss: 0.2166 - val_accuracy: 0.9310\n",
      "Epoch 618/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2930 - accuracy: 0.8732 - val_loss: 0.2163 - val_accuracy: 0.9326\n",
      "Epoch 619/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2924 - accuracy: 0.8739 - val_loss: 0.2149 - val_accuracy: 0.9318\n",
      "Epoch 620/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2955 - accuracy: 0.8698 - val_loss: 0.2134 - val_accuracy: 0.9326\n",
      "Epoch 621/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2913 - accuracy: 0.8688 - val_loss: 0.2128 - val_accuracy: 0.9326\n",
      "Epoch 622/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2918 - accuracy: 0.8739 - val_loss: 0.2127 - val_accuracy: 0.9318\n",
      "Epoch 623/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2927 - accuracy: 0.8672 - val_loss: 0.2124 - val_accuracy: 0.9310\n",
      "Epoch 624/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2945 - accuracy: 0.8684 - val_loss: 0.2127 - val_accuracy: 0.9310\n",
      "Epoch 625/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2861 - accuracy: 0.8740 - val_loss: 0.2130 - val_accuracy: 0.9310\n",
      "Epoch 626/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2868 - accuracy: 0.8735 - val_loss: 0.2125 - val_accuracy: 0.9310\n",
      "Epoch 627/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2902 - accuracy: 0.8720 - val_loss: 0.2121 - val_accuracy: 0.9310\n",
      "Epoch 628/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.2950 - accuracy: 0.8715 - val_loss: 0.2122 - val_accuracy: 0.9334\n",
      "Epoch 629/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2930 - accuracy: 0.8716 - val_loss: 0.2123 - val_accuracy: 0.9334\n",
      "Epoch 630/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2880 - accuracy: 0.8734 - val_loss: 0.2127 - val_accuracy: 0.9342\n",
      "Epoch 631/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2931 - accuracy: 0.8700 - val_loss: 0.2127 - val_accuracy: 0.9342\n",
      "Epoch 632/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.3059 - accuracy: 0.8632 - val_loss: 0.2112 - val_accuracy: 0.9357\n",
      "Epoch 633/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2925 - accuracy: 0.8732 - val_loss: 0.2098 - val_accuracy: 0.9365\n",
      "Epoch 634/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2887 - accuracy: 0.8742 - val_loss: 0.2093 - val_accuracy: 0.9373\n",
      "Epoch 635/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2914 - accuracy: 0.8698 - val_loss: 0.2091 - val_accuracy: 0.9389\n",
      "Epoch 636/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.2936 - accuracy: 0.8698 - val_loss: 0.2089 - val_accuracy: 0.9404\n",
      "Epoch 637/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2837 - accuracy: 0.8780 - val_loss: 0.2085 - val_accuracy: 0.9404\n",
      "Epoch 638/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2874 - accuracy: 0.8748 - val_loss: 0.2079 - val_accuracy: 0.9404\n",
      "Epoch 639/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2851 - accuracy: 0.8787 - val_loss: 0.2083 - val_accuracy: 0.9397\n",
      "Epoch 640/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2875 - accuracy: 0.8754 - val_loss: 0.2087 - val_accuracy: 0.9389\n",
      "Epoch 641/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2896 - accuracy: 0.8724 - val_loss: 0.2086 - val_accuracy: 0.9381\n",
      "Epoch 642/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2860 - accuracy: 0.8731 - val_loss: 0.2076 - val_accuracy: 0.9381\n",
      "Epoch 643/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2932 - accuracy: 0.8699 - val_loss: 0.2062 - val_accuracy: 0.9373\n",
      "Epoch 644/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2912 - accuracy: 0.8713 - val_loss: 0.2052 - val_accuracy: 0.9412\n",
      "Epoch 645/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2917 - accuracy: 0.8729 - val_loss: 0.2041 - val_accuracy: 0.9436\n",
      "Epoch 646/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2828 - accuracy: 0.8770 - val_loss: 0.2040 - val_accuracy: 0.9436\n",
      "Epoch 647/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2834 - accuracy: 0.8763 - val_loss: 0.2047 - val_accuracy: 0.9436\n",
      "Epoch 648/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2847 - accuracy: 0.8741 - val_loss: 0.2056 - val_accuracy: 0.9389\n",
      "Epoch 649/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2938 - accuracy: 0.8690 - val_loss: 0.2069 - val_accuracy: 0.9373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2902 - accuracy: 0.8724 - val_loss: 0.2087 - val_accuracy: 0.9342\n",
      "Epoch 651/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2852 - accuracy: 0.8744 - val_loss: 0.2096 - val_accuracy: 0.9334\n",
      "Epoch 652/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2816 - accuracy: 0.8737 - val_loss: 0.2096 - val_accuracy: 0.9334\n",
      "Epoch 653/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2885 - accuracy: 0.8716 - val_loss: 0.2098 - val_accuracy: 0.9326\n",
      "Epoch 654/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2841 - accuracy: 0.8772 - val_loss: 0.2100 - val_accuracy: 0.9326\n",
      "Epoch 655/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2896 - accuracy: 0.8712 - val_loss: 0.2100 - val_accuracy: 0.9334\n",
      "Epoch 656/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2798 - accuracy: 0.8753 - val_loss: 0.2103 - val_accuracy: 0.9326\n",
      "Epoch 657/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2817 - accuracy: 0.8742 - val_loss: 0.2107 - val_accuracy: 0.9326\n",
      "Epoch 658/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2843 - accuracy: 0.8745 - val_loss: 0.2108 - val_accuracy: 0.9310\n",
      "Epoch 659/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2898 - accuracy: 0.8734 - val_loss: 0.2103 - val_accuracy: 0.9326\n",
      "Epoch 660/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2913 - accuracy: 0.8720 - val_loss: 0.2091 - val_accuracy: 0.9326\n",
      "Epoch 661/800\n",
      "11480/11480 [==============================] - 0s 27us/sample - loss: 0.2809 - accuracy: 0.8759 - val_loss: 0.2074 - val_accuracy: 0.9365\n",
      "Epoch 662/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2796 - accuracy: 0.8794 - val_loss: 0.2050 - val_accuracy: 0.9389\n",
      "Epoch 663/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2854 - accuracy: 0.8780 - val_loss: 0.2019 - val_accuracy: 0.9389\n",
      "Epoch 664/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2786 - accuracy: 0.8785 - val_loss: 0.1981 - val_accuracy: 0.9404\n",
      "Epoch 665/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2873 - accuracy: 0.8723 - val_loss: 0.1953 - val_accuracy: 0.9412\n",
      "Epoch 666/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2813 - accuracy: 0.8777 - val_loss: 0.1947 - val_accuracy: 0.9412\n",
      "Epoch 667/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2845 - accuracy: 0.8733 - val_loss: 0.1953 - val_accuracy: 0.9412\n",
      "Epoch 668/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2833 - accuracy: 0.8792 - val_loss: 0.1974 - val_accuracy: 0.9397\n",
      "Epoch 669/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2785 - accuracy: 0.8765 - val_loss: 0.1998 - val_accuracy: 0.9389\n",
      "Epoch 670/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2868 - accuracy: 0.8743 - val_loss: 0.2017 - val_accuracy: 0.9381\n",
      "Epoch 671/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2824 - accuracy: 0.8770 - val_loss: 0.2014 - val_accuracy: 0.9397\n",
      "Epoch 672/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2780 - accuracy: 0.8762 - val_loss: 0.1997 - val_accuracy: 0.9428\n",
      "Epoch 673/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2831 - accuracy: 0.8767 - val_loss: 0.1976 - val_accuracy: 0.9451\n",
      "Epoch 674/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2761 - accuracy: 0.8787 - val_loss: 0.1949 - val_accuracy: 0.9451\n",
      "Epoch 675/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2794 - accuracy: 0.8790 - val_loss: 0.1929 - val_accuracy: 0.9444\n",
      "Epoch 676/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2832 - accuracy: 0.8738 - val_loss: 0.1917 - val_accuracy: 0.9451\n",
      "Epoch 677/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2824 - accuracy: 0.8785 - val_loss: 0.1922 - val_accuracy: 0.9451\n",
      "Epoch 678/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2818 - accuracy: 0.8720 - val_loss: 0.1940 - val_accuracy: 0.9451\n",
      "Epoch 679/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2890 - accuracy: 0.8736 - val_loss: 0.1964 - val_accuracy: 0.9451\n",
      "Epoch 680/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2802 - accuracy: 0.8786 - val_loss: 0.1990 - val_accuracy: 0.9428\n",
      "Epoch 681/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2817 - accuracy: 0.8753 - val_loss: 0.2013 - val_accuracy: 0.9412\n",
      "Epoch 682/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2769 - accuracy: 0.8787 - val_loss: 0.2024 - val_accuracy: 0.9389\n",
      "Epoch 683/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2870 - accuracy: 0.8709 - val_loss: 0.2021 - val_accuracy: 0.9397\n",
      "Epoch 684/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2850 - accuracy: 0.8741 - val_loss: 0.2013 - val_accuracy: 0.9420\n",
      "Epoch 685/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2816 - accuracy: 0.8762 - val_loss: 0.2004 - val_accuracy: 0.9436\n",
      "Epoch 686/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2773 - accuracy: 0.8765 - val_loss: 0.1991 - val_accuracy: 0.9451\n",
      "Epoch 687/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2804 - accuracy: 0.8767 - val_loss: 0.1980 - val_accuracy: 0.9444\n",
      "Epoch 688/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2770 - accuracy: 0.8781 - val_loss: 0.1979 - val_accuracy: 0.9444\n",
      "Epoch 689/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2785 - accuracy: 0.8790 - val_loss: 0.1982 - val_accuracy: 0.9444\n",
      "Epoch 690/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2752 - accuracy: 0.8799 - val_loss: 0.1982 - val_accuracy: 0.9436\n",
      "Epoch 691/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2835 - accuracy: 0.8773 - val_loss: 0.1983 - val_accuracy: 0.9428\n",
      "Epoch 692/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2807 - accuracy: 0.8767 - val_loss: 0.1989 - val_accuracy: 0.9420\n",
      "Epoch 693/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2783 - accuracy: 0.8767 - val_loss: 0.1990 - val_accuracy: 0.9404\n",
      "Epoch 694/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2779 - accuracy: 0.8780 - val_loss: 0.1980 - val_accuracy: 0.9420\n",
      "Epoch 695/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2747 - accuracy: 0.8809 - val_loss: 0.1969 - val_accuracy: 0.9420\n",
      "Epoch 696/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2797 - accuracy: 0.8763 - val_loss: 0.1955 - val_accuracy: 0.9428\n",
      "Epoch 697/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2830 - accuracy: 0.8753 - val_loss: 0.1935 - val_accuracy: 0.9436\n",
      "Epoch 698/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2753 - accuracy: 0.8795 - val_loss: 0.1922 - val_accuracy: 0.9436\n",
      "Epoch 699/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2765 - accuracy: 0.8801 - val_loss: 0.1921 - val_accuracy: 0.9436\n",
      "Epoch 700/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2751 - accuracy: 0.8795 - val_loss: 0.1930 - val_accuracy: 0.9436\n",
      "Epoch 701/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2743 - accuracy: 0.8788 - val_loss: 0.1944 - val_accuracy: 0.9428\n",
      "Epoch 702/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2793 - accuracy: 0.8767 - val_loss: 0.1956 - val_accuracy: 0.9428\n",
      "Epoch 703/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2795 - accuracy: 0.8782 - val_loss: 0.1962 - val_accuracy: 0.9428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 704/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2784 - accuracy: 0.8777 - val_loss: 0.1961 - val_accuracy: 0.9428\n",
      "Epoch 705/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2749 - accuracy: 0.8774 - val_loss: 0.1962 - val_accuracy: 0.9436\n",
      "Epoch 706/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2700 - accuracy: 0.8834 - val_loss: 0.1975 - val_accuracy: 0.9459\n",
      "Epoch 707/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2714 - accuracy: 0.8821 - val_loss: 0.1979 - val_accuracy: 0.9467\n",
      "Epoch 708/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2751 - accuracy: 0.8827 - val_loss: 0.1972 - val_accuracy: 0.9475\n",
      "Epoch 709/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2725 - accuracy: 0.8836 - val_loss: 0.1966 - val_accuracy: 0.9483\n",
      "Epoch 710/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2706 - accuracy: 0.8796 - val_loss: 0.1954 - val_accuracy: 0.9475\n",
      "Epoch 711/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2680 - accuracy: 0.8829 - val_loss: 0.1949 - val_accuracy: 0.9459\n",
      "Epoch 712/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2763 - accuracy: 0.8776 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 713/800\n",
      "11480/11480 [==============================] - 0s 37us/sample - loss: 0.2700 - accuracy: 0.8807 - val_loss: 0.1911 - val_accuracy: 0.9491\n",
      "Epoch 714/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2780 - accuracy: 0.8817 - val_loss: 0.1895 - val_accuracy: 0.9491\n",
      "Epoch 715/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.2772 - accuracy: 0.8812 - val_loss: 0.1887 - val_accuracy: 0.9491\n",
      "Epoch 716/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2764 - accuracy: 0.8783 - val_loss: 0.1881 - val_accuracy: 0.9491\n",
      "Epoch 717/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2747 - accuracy: 0.8828 - val_loss: 0.1894 - val_accuracy: 0.9483\n",
      "Epoch 718/800\n",
      "11480/11480 [==============================] - 0s 43us/sample - loss: 0.2694 - accuracy: 0.8821 - val_loss: 0.1910 - val_accuracy: 0.9467\n",
      "Epoch 719/800\n",
      "11480/11480 [==============================] - 1s 58us/sample - loss: 0.2718 - accuracy: 0.8786 - val_loss: 0.1922 - val_accuracy: 0.9467\n",
      "Epoch 720/800\n",
      "11480/11480 [==============================] - 1s 57us/sample - loss: 0.2783 - accuracy: 0.8738 - val_loss: 0.1932 - val_accuracy: 0.9467\n",
      "Epoch 721/800\n",
      "11480/11480 [==============================] - 1s 58us/sample - loss: 0.2732 - accuracy: 0.8821 - val_loss: 0.1939 - val_accuracy: 0.9459\n",
      "Epoch 722/800\n",
      "11480/11480 [==============================] - 1s 56us/sample - loss: 0.2716 - accuracy: 0.8815 - val_loss: 0.1935 - val_accuracy: 0.9459\n",
      "Epoch 723/800\n",
      "11480/11480 [==============================] - 1s 57us/sample - loss: 0.2698 - accuracy: 0.8802 - val_loss: 0.1920 - val_accuracy: 0.9467\n",
      "Epoch 724/800\n",
      "11480/11480 [==============================] - 1s 56us/sample - loss: 0.2718 - accuracy: 0.8860 - val_loss: 0.1907 - val_accuracy: 0.9491\n",
      "Epoch 725/800\n",
      "11480/11480 [==============================] - 1s 54us/sample - loss: 0.2769 - accuracy: 0.8785 - val_loss: 0.1904 - val_accuracy: 0.9506\n",
      "Epoch 726/800\n",
      "11480/11480 [==============================] - 1s 55us/sample - loss: 0.2803 - accuracy: 0.8817 - val_loss: 0.1904 - val_accuracy: 0.9498\n",
      "Epoch 727/800\n",
      "11480/11480 [==============================] - 1s 53us/sample - loss: 0.2671 - accuracy: 0.8857 - val_loss: 0.1911 - val_accuracy: 0.9498\n",
      "Epoch 728/800\n",
      "11480/11480 [==============================] - 1s 52us/sample - loss: 0.2672 - accuracy: 0.8876 - val_loss: 0.1918 - val_accuracy: 0.9491\n",
      "Epoch 729/800\n",
      "11480/11480 [==============================] - 1s 55us/sample - loss: 0.2706 - accuracy: 0.8780 - val_loss: 0.1927 - val_accuracy: 0.9491\n",
      "Epoch 730/800\n",
      "11480/11480 [==============================] - 1s 54us/sample - loss: 0.2694 - accuracy: 0.8840 - val_loss: 0.1933 - val_accuracy: 0.9483\n",
      "Epoch 731/800\n",
      "11480/11480 [==============================] - 1s 56us/sample - loss: 0.2692 - accuracy: 0.8823 - val_loss: 0.1929 - val_accuracy: 0.9475\n",
      "Epoch 732/800\n",
      "11480/11480 [==============================] - 1s 56us/sample - loss: 0.2648 - accuracy: 0.8873 - val_loss: 0.1924 - val_accuracy: 0.9483\n",
      "Epoch 733/800\n",
      "11480/11480 [==============================] - 1s 52us/sample - loss: 0.2673 - accuracy: 0.8833 - val_loss: 0.1917 - val_accuracy: 0.9467\n",
      "Epoch 734/800\n",
      "11480/11480 [==============================] - 1s 53us/sample - loss: 0.2673 - accuracy: 0.8835 - val_loss: 0.1884 - val_accuracy: 0.9467\n",
      "Epoch 735/800\n",
      "11480/11480 [==============================] - 1s 52us/sample - loss: 0.2735 - accuracy: 0.8829 - val_loss: 0.1858 - val_accuracy: 0.9467\n",
      "Epoch 736/800\n",
      "11480/11480 [==============================] - 1s 52us/sample - loss: 0.2697 - accuracy: 0.8822 - val_loss: 0.1839 - val_accuracy: 0.9491\n",
      "Epoch 737/800\n",
      "11480/11480 [==============================] - 1s 53us/sample - loss: 0.2718 - accuracy: 0.8789 - val_loss: 0.1833 - val_accuracy: 0.9506\n",
      "Epoch 738/800\n",
      "11480/11480 [==============================] - 1s 52us/sample - loss: 0.2711 - accuracy: 0.8821 - val_loss: 0.1831 - val_accuracy: 0.9506\n",
      "Epoch 739/800\n",
      "11480/11480 [==============================] - 1s 53us/sample - loss: 0.2634 - accuracy: 0.8846 - val_loss: 0.1835 - val_accuracy: 0.9483\n",
      "Epoch 740/800\n",
      "11480/11480 [==============================] - 95s 8ms/sample - loss: 0.2686 - accuracy: 0.8837 - val_loss: 0.1853 - val_accuracy: 0.9475\n",
      "Epoch 741/800\n",
      "11480/11480 [==============================] - 0s 24us/sample - loss: 0.2686 - accuracy: 0.8814 - val_loss: 0.1870 - val_accuracy: 0.9475\n",
      "Epoch 742/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2756 - accuracy: 0.8806 - val_loss: 0.1876 - val_accuracy: 0.9475\n",
      "Epoch 743/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2685 - accuracy: 0.8834 - val_loss: 0.1874 - val_accuracy: 0.9475\n",
      "Epoch 744/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2656 - accuracy: 0.8829 - val_loss: 0.1865 - val_accuracy: 0.9483\n",
      "Epoch 745/800\n",
      "11480/11480 [==============================] - 0s 24us/sample - loss: 0.2667 - accuracy: 0.8871 - val_loss: 0.1854 - val_accuracy: 0.9491\n",
      "Epoch 746/800\n",
      "11480/11480 [==============================] - 0s 21us/sample - loss: 0.2689 - accuracy: 0.8804 - val_loss: 0.1858 - val_accuracy: 0.9483\n",
      "Epoch 747/800\n",
      "11480/11480 [==============================] - 0s 22us/sample - loss: 0.2706 - accuracy: 0.8814 - val_loss: 0.1857 - val_accuracy: 0.9491\n",
      "Epoch 748/800\n",
      "11480/11480 [==============================] - 0s 22us/sample - loss: 0.2649 - accuracy: 0.8823 - val_loss: 0.1865 - val_accuracy: 0.9491\n",
      "Epoch 749/800\n",
      "11480/11480 [==============================] - 0s 21us/sample - loss: 0.2681 - accuracy: 0.8861 - val_loss: 0.1881 - val_accuracy: 0.9491\n",
      "Epoch 750/800\n",
      "11480/11480 [==============================] - 0s 20us/sample - loss: 0.2659 - accuracy: 0.8853 - val_loss: 0.1889 - val_accuracy: 0.9475\n",
      "Epoch 751/800\n",
      "11480/11480 [==============================] - 0s 21us/sample - loss: 0.2681 - accuracy: 0.8821 - val_loss: 0.1886 - val_accuracy: 0.9483\n",
      "Epoch 752/800\n",
      "11480/11480 [==============================] - 0s 22us/sample - loss: 0.2624 - accuracy: 0.8875 - val_loss: 0.1877 - val_accuracy: 0.9491\n",
      "Epoch 753/800\n",
      "11480/11480 [==============================] - 0s 21us/sample - loss: 0.2664 - accuracy: 0.8827 - val_loss: 0.1873 - val_accuracy: 0.9498\n",
      "Epoch 754/800\n",
      "11480/11480 [==============================] - 0s 24us/sample - loss: 0.2667 - accuracy: 0.8833 - val_loss: 0.1882 - val_accuracy: 0.9491\n",
      "Epoch 755/800\n",
      "11480/11480 [==============================] - 0s 21us/sample - loss: 0.2688 - accuracy: 0.8838 - val_loss: 0.1880 - val_accuracy: 0.9483\n",
      "Epoch 756/800\n",
      "11480/11480 [==============================] - 0s 21us/sample - loss: 0.2675 - accuracy: 0.8830 - val_loss: 0.1870 - val_accuracy: 0.9483\n",
      "Epoch 757/800\n",
      "11480/11480 [==============================] - 0s 22us/sample - loss: 0.2660 - accuracy: 0.8849 - val_loss: 0.1861 - val_accuracy: 0.9491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2599 - accuracy: 0.8863 - val_loss: 0.1858 - val_accuracy: 0.9491\n",
      "Epoch 759/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2693 - accuracy: 0.8831 - val_loss: 0.1853 - val_accuracy: 0.9498\n",
      "Epoch 760/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.2652 - accuracy: 0.8845 - val_loss: 0.1852 - val_accuracy: 0.9498\n",
      "Epoch 761/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.2646 - accuracy: 0.8861 - val_loss: 0.1861 - val_accuracy: 0.9475\n",
      "Epoch 762/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2616 - accuracy: 0.8846 - val_loss: 0.1864 - val_accuracy: 0.9483\n",
      "Epoch 763/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.2607 - accuracy: 0.8881 - val_loss: 0.1853 - val_accuracy: 0.9514\n",
      "Epoch 764/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2656 - accuracy: 0.8857 - val_loss: 0.1831 - val_accuracy: 0.9522\n",
      "Epoch 765/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2637 - accuracy: 0.8858 - val_loss: 0.1810 - val_accuracy: 0.9514\n",
      "Epoch 766/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2668 - accuracy: 0.8852 - val_loss: 0.1794 - val_accuracy: 0.9545\n",
      "Epoch 767/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.2611 - accuracy: 0.8859 - val_loss: 0.1793 - val_accuracy: 0.9545\n",
      "Epoch 768/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2636 - accuracy: 0.8870 - val_loss: 0.1796 - val_accuracy: 0.9545\n",
      "Epoch 769/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2552 - accuracy: 0.8877 - val_loss: 0.1805 - val_accuracy: 0.9545\n",
      "Epoch 770/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2674 - accuracy: 0.8827 - val_loss: 0.1801 - val_accuracy: 0.9545\n",
      "Epoch 771/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2688 - accuracy: 0.8829 - val_loss: 0.1789 - val_accuracy: 0.9553\n",
      "Epoch 772/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2687 - accuracy: 0.8844 - val_loss: 0.1785 - val_accuracy: 0.9545\n",
      "Epoch 773/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2589 - accuracy: 0.8867 - val_loss: 0.1776 - val_accuracy: 0.9530\n",
      "Epoch 774/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2688 - accuracy: 0.8818 - val_loss: 0.1774 - val_accuracy: 0.9530\n",
      "Epoch 775/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2692 - accuracy: 0.8808 - val_loss: 0.1771 - val_accuracy: 0.9538\n",
      "Epoch 776/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2627 - accuracy: 0.8874 - val_loss: 0.1772 - val_accuracy: 0.9522\n",
      "Epoch 777/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2588 - accuracy: 0.8884 - val_loss: 0.1761 - val_accuracy: 0.9530\n",
      "Epoch 778/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2680 - accuracy: 0.8826 - val_loss: 0.1756 - val_accuracy: 0.9530\n",
      "Epoch 779/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2562 - accuracy: 0.8925 - val_loss: 0.1750 - val_accuracy: 0.9538\n",
      "Epoch 780/800\n",
      "11480/11480 [==============================] - 0s 31us/sample - loss: 0.2649 - accuracy: 0.8863 - val_loss: 0.1751 - val_accuracy: 0.9530\n",
      "Epoch 781/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2596 - accuracy: 0.8866 - val_loss: 0.1751 - val_accuracy: 0.9538\n",
      "Epoch 782/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2621 - accuracy: 0.8875 - val_loss: 0.1758 - val_accuracy: 0.9530\n",
      "Epoch 783/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2603 - accuracy: 0.8888 - val_loss: 0.1766 - val_accuracy: 0.9522\n",
      "Epoch 784/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2586 - accuracy: 0.8875 - val_loss: 0.1778 - val_accuracy: 0.9522\n",
      "Epoch 785/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2554 - accuracy: 0.8889 - val_loss: 0.1786 - val_accuracy: 0.9514\n",
      "Epoch 786/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2687 - accuracy: 0.8843 - val_loss: 0.1782 - val_accuracy: 0.9514\n",
      "Epoch 787/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2583 - accuracy: 0.8874 - val_loss: 0.1786 - val_accuracy: 0.9514\n",
      "Epoch 788/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2671 - accuracy: 0.8817 - val_loss: 0.1794 - val_accuracy: 0.9514\n",
      "Epoch 789/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2612 - accuracy: 0.8849 - val_loss: 0.1797 - val_accuracy: 0.9506\n",
      "Epoch 790/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2585 - accuracy: 0.8863 - val_loss: 0.1801 - val_accuracy: 0.9522\n",
      "Epoch 791/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2572 - accuracy: 0.8920 - val_loss: 0.1798 - val_accuracy: 0.9530\n",
      "Epoch 792/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2544 - accuracy: 0.8895 - val_loss: 0.1785 - val_accuracy: 0.9530\n",
      "Epoch 793/800\n",
      "11480/11480 [==============================] - 0s 28us/sample - loss: 0.2582 - accuracy: 0.8870 - val_loss: 0.1770 - val_accuracy: 0.9538\n",
      "Epoch 794/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2558 - accuracy: 0.8862 - val_loss: 0.1758 - val_accuracy: 0.9522\n",
      "Epoch 795/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2559 - accuracy: 0.8905 - val_loss: 0.1744 - val_accuracy: 0.9514\n",
      "Epoch 796/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2587 - accuracy: 0.8883 - val_loss: 0.1733 - val_accuracy: 0.9506\n",
      "Epoch 797/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2513 - accuracy: 0.8915 - val_loss: 0.1741 - val_accuracy: 0.9498\n",
      "Epoch 798/800\n",
      "11480/11480 [==============================] - 0s 29us/sample - loss: 0.2571 - accuracy: 0.8909 - val_loss: 0.1755 - val_accuracy: 0.9522\n",
      "Epoch 799/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2571 - accuracy: 0.8885 - val_loss: 0.1764 - val_accuracy: 0.9506\n",
      "Epoch 800/800\n",
      "11480/11480 [==============================] - 0s 30us/sample - loss: 0.2502 - accuracy: 0.8909 - val_loss: 0.1759 - val_accuracy: 0.9506\n"
     ]
    }
   ],
   "source": [
    "epochs = 800\n",
    "batch_size = 12756\n",
    "\n",
    "history = model.fit(Xs_train, ytrain, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=1)\n",
    "loss,accuracy  = model.evaluate(Xs_test, ytest, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25c96bf8a08>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25c96c75208>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3hUZdr48e89k0kP6fSE0EEBAQGxoCw2sKDuqovKrvpbZXV13aKuuu/q6va+vu76Wteya9e1oKKCvUsRpPeaQEiBhCSkzczz++M5k0waBMxkQs79ua5cM+fMmXPuCeHc83QxxqCUUsq9PNEOQCmlVHRpIlBKKZfTRKCUUi6niUAppVxOE4FSSrmcJgKllHI5TQTKNUTkMRH5TTuP3Soip0U6JqW6Ak0ESh0mEblTRIyITIp2LEp9HZoIlDoMIiLAd4A9wOWdfW0R0f+7qsPoH5PqUpwqmZtFZLmIVInIv0Skl4i8ISIVIvK2iKSHHT9TRFaJSJmIvC8iI8NeGyciXzrvexaIb3atc0RkmfPeT0VkzCGEOgXoC/wImCUisc3OfbWIrHGuvVpExjv7c0TkRREpFpFSEfmns/9OEXki7P15Tmkjxtl+X0R+KyKfAPuBQSJyZdg1NovI95vFcJ7z+faJyCYRmS4iF4nIkmbH3SgiLx/CZ1fdjCYC1RV9CzgdGAacC7wB/BzIwv7N3gAgIsOAp4EfA9nAPOBVEYl1bswvA/8BMoDnnfPivHc88AjwfSATeACYKyJx7YzxcuBV4Fln+5ywc18E3Al8F+gBzARKRcQLvAZsA/KAfsAz7bwe2BLIHCDFOUeRc90ewJXA38MSziTg38DNQBpwMrAVmAsMDE+YwGzs70m5lCYC1RX9wxiz2xhTAHwEfGGMWWqMqQVeAsY5x30beN0Ys8AYUw/8BUgATgAmAz7gbmNMvTHmBWBR2DWuBh4wxnxhjAkYYx4Hap33HZCIJAIXAU85132BptVDVwF/MsYsMtZGY8w2YBK2FHGzMabKGFNjjPn4EH4vjxljVhlj/M5net0Ys8m5xgfAfGxJBeB7wCPO7yZojCkwxqx1fofPYm/+iMjR2KT02iHEoboZTQSqK9od9ry6le1k53lf7DdjAIwxQWAH9pt2X6DANJ1VcVvY8wHAjU61UJmIlAE5zvsO5gLAjy2BADwJzBCRbGc7B9jUyvtygG3GGH87rtGaHeEbIjJDRD4XkT1O/GdhS00HigHgceDSsHaO55wEoVxKE4E6ku3E3tCBhgbcHKAA2AX0c/aF5IY93wH81hiTFvaTaIx5uh3XvRybjLaLSCG22skHXBJ27sGtvG8HkBuq92+mCkgM2+7dyjENSc2pwvovthTUyxiThk1Moc/bVgwYYz4H6rClh0vRaiHX00SgjmTPAWeLyKki4gNuxFbvfAp8hv3WfoOIxIjIN7FVMyEPAdeIyHFOL5wkETlbRFIOdEER6Qeciq2bH+v8HAP8kcbqoYeBm0TkWOfcQ0RkALAQm6D+4FwvXkROdN6zDDhZRHJFJBW47SCfPRaIA4oBv4jMAM4Ie/1fwJXO78YjIv1EZETY6/8G/gn4D7F6SnVDmgjUEcsYsw5b1/0PoATbsHyuMabOGFMHfBO4AtiLbU94Mey9i7HtBP90Xt/oHHsw3wGWGWPmG2MKQz/APcAYERlljHke+C3wFFCBbbTOMMYEnBiHANuBfCcujDELsHX3y4ElHKTO3hhTgW00f86J/1JsQ3Do9YU4DchAOfABYaUnbClgFFoaUIDowjRKuY+IJGB7HY03xmyIdjwqurREoJQ7XQss0iSgIIKJQEQeEZEiEVnZxusiIveIyEaxg4fGRyoWpVQjEdmKHQh3Y5RDUV1EJEsEjwHTD/D6DGCo8zMHuC+CsSilHMaYPGPMAGPM0mjHorqGiCUCY8yH2HlY2nIe8G9nMMznQJqI9IlUPEoppVrXWn/mztKPpgNk8p19uw70pqysLJOXlxfBsJRSqvtZsmRJiTEmu7XXopkIpJV9rXZhEpE52OojcnNzWbx4cSTjUkqpbkdEtrX1WjR7DeVjR4GG9MeOFG3BGPOgMWaCMWZCdnarCU0ppdRhimYimAt81+k9NBkoN8YcsFpIKaVUx4tY1ZCIPA1MBbJEJB/4JXY+Fowx92PnRTkLO6JzP3YUpFJKqU4WsURgjLnkIK8b4LqOuFZ9fT35+fnU1NR0xOm6rPj4ePr374/P54t2KEqpbiSajcUdJj8/n5SUFPLy8mg62WT3YYyhtLSU/Px8Bg4cGO1wlFLdSLeYYqKmpobMzMxumwQARITMzMxuX+pRSnW+bpEIgG6dBELc8BmVUp2vW1QNKaXUEWXnUtizGapKYMAJkJoDQT8EA5DSq/G42goQD8QmRTQcTQQdoKysjKeeeoof/OAHh/S+s846i6eeeoq0tLQIRaaU6hAVheCvgdRc8HjsjXz3Kug3AbKHgzGw7AnIHAoDjoeafVC9F+JT7Q2/Rz+o3A2VRfDpPbDlg7avlTUceo6EXV/B3i32vXEp0H8iTPwe9B3X9nsPkyaCDlBWVsb//d//tUgEgUAAr9fb5vvmzZvX5mtKqQ4UqIctH9rHuGTIPQHqq6B4PWQMhMSMlu9ZPRc+/DMULm/clz0C8qbA0ifAX233eWKgR18o2263e42C3a1Outyo3wSY8Ufw+mDVy/aGnzEYgvVQ8KW95v5SGH2xfV681v70HaeJoKu69dZb2bRpE2PHjsXn85GcnEyfPn1YtmwZq1ev5vzzz2fHjh3U1NTwox/9iDlz5gCQl5fH4sWLqaysZMaMGZx00kl8+umn9OvXj1deeYWEhIQofzKlupjaSihYbL8111XBUxfZKpWr34OkrKbHFq2Bze9DznHwxf2w/NnG10ZfbL/RF60CBLKG2Zv5TmdC1vQ82LXMPiZkwLAzoedRsPQ/sPgRyBwCZ/wa9m61560qgYlX2URTudteM3MIFK6AnEl2X3Ive1PvMxaOvbwxlj7HtP5ZjQER+7hvJ6T0pvWZeb6+I26FsgkTJpjmcw2tWbOGkSNHAnDXq6tYvXNfh17zqL49+OW5R7f5+tatWznnnHNYuXIl77//PmeffTYrV65s6Oa5Z88eMjIyqK6uZuLEiXzwwQdkZmY2SQRDhgxh8eLFjB07losvvpiZM2cye/bsFtcK/6xKucq2z+DVG6Bkvf0WHvQ3vjb5Opj+u8btBb+ET+5u+v6jL4Dxl8O6ebDwQbvv+Ovtt/IvHgQTsMeIByp2QcYgOP1XEJNgq4NC/HX2PUdY5w0RWWKMmdDaa1oiiIBJkyY16et/zz338NJLLwGwY8cONmzYQGZmZpP3DBw4kLFjxwJw7LHHsnXr1k6LV6lOt+plW1UT9MPx19k6dfHYhtLidbDxHYiJhcHT7LfqZU/Z6pbELDjv3sZv++Nmw67l8Pm9ti4+NtG+VrTavveM39pv7PX77fOYWBh4sm2c7Tce8k6y8Rx3rX1vXMrBY4+JjeivJhq6XSI40Df3zpKU1NjC//777/P222/z2WefkZiYyNSpU1sdCxAXF9fw3Ov1Ul1d3SmxKhVxwaB99Hhsdc6Sx+Ctnze+/uXjbb/347/bx+TeMPXncMIP7Q07XG0FmKBNLFXFtp69R3+48FFISIPT72p6vMcLJ97QdF94Tx0X6naJIBpSUlKoqKho9bXy8nLS09NJTExk7dq1fP75550cnVIRFAzam29rN9KqEnvT/+Qe2/1x8jWw6GHbqNrzKLjqbdsbZ8N8SMuF/Xtsg6g3FsZ/1/a42fmlLSkMOBFi4lpeA+y3+G8+YJ8bY0sOPY+yN3zVLpoIOkBmZiYnnngio0aNIiEhgV69Gv9TTJ8+nfvvv58xY8YwfPhwJk+eHMVIlToMVSX25pp3MlQW2t4svUfbG/fTs2DHQtu10eO1VT07l9pv8JWFdnvgyVBeAAvusPXts56GoafbevbMwZB5bdvXHnLaocUqYmNTh6TbNRZ3d276rCpKtn1mv5lXFtnqlsLlULsPknpC9R57c+8/EfIXgXhtXXt9je1OWbEbBp1iv8WnD4BhM+yAKRO0fefTBtibv+p02lislGrdxndsL5qKQvtNumw7LHuy6THDptuumfv32C6WFYWw7g372ll/st0mQ0JdHpsTr228VV2SJgKluouK3VCeDx/9xdavH3+dvbn7a+GrZ2zvmaLVttF19IXwxs9gxfP2Jp2QBmtfg9gUO2Bp7GUwciYk92z9xu6vs104Pc2mKzvCulQqSxOBUkcCY+w398oiO7DIX2sbaYvW2MFKBUts3/cQT4y98WcNB1+8M1BK7Aja+f8DH/3Vvu/km+Gkn9jG3NpK8CW0r5G1G3ahdDNNBEpFU8kGO+I0voedm6ZojW1YDfqhbJsdhZq/CDa8ZfvTtyY+DXKPt/PTpOfZvvUpfeHZ2XYULtiBUxP+H8T1gKcutvPYnH8fjA1bPyouOeIfV3VNmgiUiiRjbJ16jz6N++prYMHtttvk3q2QmAlJ2bBnCwRqWz9P79Fw2p0wZpZNCB6v/fYen2q/9Xtb+a98xet2DpvELEjObtx/9bsQqGu7O6bqdLX+ANc9+SU/nDaUMf1TAVi0dS9vrizk5GFZvLmykIKyan53wWhyMhIPcrZDp4lAqcNVW2EHSMXEQ2yyvTmvfhk+vtvOXXPq7fD6TfbbfFwqZA21c8ysfgU2vm0nLxszC/IX2vMNmmq7WiZm2V42iZm28bb36Kb99MOTyoH44m0poTkRTQJf0ycbS9hTVcfnm0vpkeDjjKN6MS43neq6AHExHv7+9nqOH5zJl9v2sqm4il+fP4q3VhZSuK+G5xbv4Jwxfdhaup8JA9Kprg/w57fWYQy8vaaoxbUe+WRLw/OPNpRw6XG5Hf55tPtoBzjcaagB7r77bubMmUNiYvuyfLQ/q3LUVsC9k2Ffvt1OzbFdI7d9bGeRLNvWOBdO5hBb/bPtk8b3T/uFrZ9XUVfnD+LzCqt27mNgVhIBY+gR7+O2F5fz8cYSduyp5soT8yitrCM1wUdlrZ+Xlha0OE//9AQKyqqJxC31ihPyOKpvDy46tv9hL1Cl3UcjrK1pqNvj7rvvZvbs2e1OBKqD1VbahtLSTfDkhbCvwN7Qv/kA9DsWAn47BcIXD0B9tR3xmjEQ3v21TQJ5U+zskZvetTNZTr3NNr6ungsvXmXr5c9xpknYt8s22vYcac+hWthWWkVWchxJca3fmmrqA3zrvk8JBA0vXHsCm4sr2VNVx9ThPVmRX05FbT3HD8rk92+s5aWlBRRX1JISF8Mlx+WyeOsevtxexojeKawtrOB3F4ymsLyaBz/azNCeKawoKG8zrkc/2XrAuI/u24NVB5jscurwbCpq/Izul8rZY/qQFBvD5pJKHv1kK0u27QXgnDF9uGfWOCpq/Jzzz4/o3SOeZ+Ycj9cT+Z5YWiLoALNmzeKVV15h+PDhnH766fTs2ZPnnnuO2tpaLrjgAu666y6qqqq4+OKLyc/PJxAIcPvtt7N7925uuukmhg8fTlZWFu+9995BrxXtz3pECgZsfXxdFSSk277zGJsAPv67nT9+X4Gtux9xtq3KCdTbm3Wogbb3GHueolV2OykbTv9108bW5soLbL977VLZqt37ali2o4xThmWzYXclCbEeTvvbh/SIj+G4QZnsraqjPmjomxpPn9QEquv9PL1wR8P70xN9VNUFqPMHOzSuUKLo1SOOR6+YxM9fWkFSnJfMpDjmfrUTgCtPzCMl3sfKgnJumT6CwdlJPPzxFs4e3YeqOj89U+KpqKlnQObBVxardj5DaqKvQz9Hc+4qEbxxa9u9Kw5X79Ew4w9tvvyHP/yBlStXsmzZMubPn88LL7zAwoULMcYwc+ZMPvzwQ4qLi+nbty+vv/46YOcgSk1N5W9/+xvvvfceWVlZbZ5ftVPFbvtNvbLITimcdxKk9LHf5nd+2fp7YhJsD5rUHLj4P3Z1qT1b4I1bYOMC2xA7/ju2140IbP3YJpQhpx28m2Vqv47/jFFWXRfgr/PXcc3UwWQlx1FcUctLS/NZuGUPF03I4RvDe/LoJ1sIGMOzi3awrXQ/p47oyR8vHMPCLXuorgvw+zfWEggG2bu/vtVr7Kvxs2D17obtr3a0PKZnShxFFW00rAOJsV7OH9ePp77YzpShWUzKy+AbI3pyzj8+bnLcmz+ewojePais9eMPBFm6vYypw7OpDxhiY+wYiZevO7Hh+G8d259FW/Zw05nDW1zzmlOajpjOSGpfF9uEWC8JsdGdF6n7JYIomz9/PvPnz2fcOLuKUGVlJRs2bGDKlCncdNNN3HLLLZxzzjlMmTIlypF2I5s/gPId9ktAXdjkfxvfto/eWDj3f22Dri/BdrWsKLT98RPS7Y09Nqnxm3vGQLjsucb94ULTFncDxhhEhOX5ZWwpqWJwdjJH9+3BhxtKOG5gBvE+e3N6bflO7py7muQ4LyP79OCNlYU8/PEWfnLaMP7+9vqG87XW0AnwztoiJvzm7Sb7jh2Q3lAlEhIb4yHW62HOyYPIyUjgJ89+BcAjV0xgza4K/vzWOgDuPPcorjhxIM8v3kG/9ARKK+tYtqOMa6cOZldZDaP69aC6PkBibAy/PX9Ukzr1Tb87i0DQUFpVS2WNn6G97LTTyU5V1DdG9HRiab0Ud8qwbE4Zlt3qa0ey7pcIDvDNvTMYY7jtttv4/ve/3+K1JUuWMG/ePG677TbOOOMM7rjjjihEeIQpXg/7S6DX0bB7te1FU1NmB0/562w/+R1f2GNjU2yXyd5jbK+YncvsoKm0nJbL+4UvTdhW//kILxj+dZXvr29SnVBZ62ddYQW5GYmkxMcQ4xFeXraT4wZmkJORyN1vr+eD9cV8Z/IAHvxwM5tLqpgwIJ1PN5W2ev7mVS8llbC1dH/D6+FJoDmvR5g2oic3TBvKxQ98RnV9AIDUBB/3zz6W4wdnsnT7Xp5ZuIMfnTaUvmktV+ObeUw/qusDJMfFMC4nnT+/tY57Lx3P2WNsr6mLJuQ0HHvuMX0ByEq2vaESY+2trXnDqtcjeD1Cn9QESG0zfNfpfomgLVUltsoge0TLYfFfU/g01GeeeSa33347l112GcnJyRQUFODz+fD7/WRkZDB79mySk5N57LHHmrxXq4aaqa2At++EL//Tet96T4yd2CxziO2B0+9YW40TXh2Te1ynhdtRivbV0CPBR019gOr6AP6A4cvte/nPZ9vYs7+Okb170KtHPAvWFLJjj12zYvbkXBas3s3ufW1XlWQlx1FSaV9fur2sYX8oCeRlJja5yYvAsQMyAEP/9ERq/QHeXFlI79QEbj5zGLkZiVx4/2eMy0njkSsmIiIYYyiqqKVXj/gm1/7olm9QXFHLiN4pTW7M43LTGZeb3mbMXo80fFNPT4pl6x/ObudvUR0q9yQCE3BuKB3fOB4+DfWMGTO49NJLOf744wFITk7miSeeYOPGjdx88814PB58Ph/33XcfAHPmzGHGjBn06dOnXY3F3VrpJjtDZclGu5RgsN6uLdt/ItSU2yqb3mNs//jUnC7bCLu3qo5Xl+/EHzBcNjmXuBgv/kAQr0eoCwTxivDXBevJSU/kogn9KSyvoaCsmnfXFvHgh5sPeO7NxVUt9j3x+fY2jx/eK4XYGA8rCsoZmJXEb84fxZNfbOOaUwYzrFcK1XUBEuO8xMV4Ka2sZc2uCsblphHv87borfL7b45psv3Fz08lxuNpuLmLSIskADYJhb6pq67JPb2GKotsz5DeY47oBSu6ba+hpU/CK2Hdb/tPhFNuhaGHOB99BKwsKGdAZiIp8S17ddQHgizPL+eY/qkU7qthza4Krv5307/PkX16sGbX4a+j3SM+hqunDGL8gHRKKmtZnl/O6p37GNIzmRtOHcqt/13OaUf1YlBWElV1ft5cWcisSblkJsU29FoJBg0iLatKlHu4q9fQQR1Zia/bKM+H/MWwaxmMPNfOsdN/op2bfuvH8PpPod8Eux5tXIrt7dPBVXgAj36yhdeW7+K/157QsG/p9r0MykqmR0JMQxVHRa2fHvF28NA5//iYrORYSirrANtnHGydfGWNn9KquoYuh63ZUlIJ2F4k++v81NQ3dneM93kYkJFErT9AUUUtc68/kQ/Xl3De2L4U7qvh042lXH3yoCbnO29s095I/7piYpPtaSNarhbm6YS+6OrI5cJEoDqVMfDJ/8L7f7ALl0DjOrQIjLnYzm2flguXPNN0TpyvaVd5Nat37mPK0GxiPEKtP8hdr64GoLy6ni0lVfzi5RWsLGj6bT3GI/iDhn5pdqQo0JAEgFYHDoUngRmjeiMC154yhLysRDwiTQZIhUrhzb+dh3rxDOlpe7JkJsdxdF9t0VSR120SQeg/Uduc147gAsERVY23bye8+xtbEtjygR19e9qddv6cgiW22+bKF+1UybknwLceOuQksKeqjg27Kzgmx9Zp+wNBlheU89pXu7hm6iCO//27bb73mLvmt/maP2iadG/sn57AlKHZfLShmPy9NjGM6J3CtyfmkJOeSHpSLCvyy5gxug/JcTFtjooNaevvVKttVLR0i0QQHx9PaWkpmZmZbf9nath9BN1MwxhjKC0tJT6+ZWNcl7H9c5h3M+zZbEsC9VW2Z8+pd8CJP2ms6ulzjH08+gI79XJC054jdf4gBkNcjJdNxZX8ft4arp4yiHG56RSUVVNaWctTC7fz4pct53uJ9XqoCwSbTNTVmnifh+u/MYS0xFj+Mn8dZc7gpheuOZ5jB6QjImwv3U9GcmxDzxWAoooa0hNjESDG21h1deyAtnu/KNXVdYvG4vr6evLz86mpqWn7jbUV9qbTo98R21gcHx9P//798fkiOxT9sGz+AJ6+xE5vfNRMO2J3xFnU5pxAXFI6q3aWExfjJTs5jvpgkHve2cCY/mnMW7GLFQXljM9NY9qInvzpzXWUVtlqmPB6+faK93m4YFw/lm4vY21hBb84eySfbSrlLxcdwxOfb+OC8f2o8weJ93mb9F0PBg1799eRqb1bVDd1oMbibpEI2mXRv2yD5I3r7IhSddiq6wJ8lV/G5EGZAKxY9AGj3ppFWXxf/tLrj9z4zZNZW7iPP76xlrWFFUwf1ZtXlu087OuFV9N8a3x/jDFMG9mTvFCPGGNI8NkukJnJsQetmlHKjbTXENgqCiAic8R2Y4GgwSPw3roiThicxc69+7nt7gdIoIbNnsWM82xitGc7BSaT8ypvpKSklidXLWhyjgMlgbgYD09cdRz/77FFTD+6N5ccl0vRvhpAyMtKZFjPlIYeL/5AsEl1jFKqY0Q0EYjIdOB/AS/wsDHmD81ezwUeB9KcY241xsyLTDChRNCxMxUeyV79aicllbXsrwuwt6qOo/r2YFivFG5+YTn+QJAhPZP5dFMp5dX1DJRdHCXbmOV9l2djVzacY5fJ4K3ABH7nv5QyTxoEDVnJcVxxwgByMhL50TPLALjsuFyOyUmjb2oCaYk+hvZKtnXwSbFkJsex4s4zDxqvJgGlIiNiiUBEvMC9wOlAPrBIROYaY1aHHfYL4DljzH0ichQwD8iLTEDdOxHU+YPs3lfTYhm7PVV1VNb42VxSic/rYWtpFV/tKCMnPZG/Lmh7rhiADUUVnOf5hLN8CznTa6vjikwaH6XOJDXeQ4++w+l91i28+eIKRgeCvHHhmIY5XkJG9LZ97of3Tmlx/tCEX0qp6IpkiWASsNEYsxlARJ4BzgPCE4EBejjPU4HDr0g+mFBvom6QCMInGzPG8NGGEl5aWtCwapII9E1t7AN/IGnxHv5n6HZ2FRYytFcKeXs+5pPMC9lc6eOqff9kUJX9Rl+ddyoJ026hZ9+x9Gy2zOHfvz22zfO3lgCUUl1LJBNBPyB8JvF8oPksYHcC80Xkh0AS0Op8AiIyB5gDkJt7mOt1hkoER1D30Y1FlXy4vpjkuBiS42N46KPNTBqYwQMfbObeS8fz0tICVhaUU7ivaW8pY2iRBH4wdTAVNX4GZyexeNteav1Brpycwwlf/hTWvmYPcsZEjdzzjvMugTN/BxOvIkHXuFWq24pkImitQ3/zu/AlwGPGmL+KyPHAf0RklDFNv7YbYx4EHgTba+jwoumaVUMbiyoBW68eNPD26t1sLK5k9c59fLyxpMXxoZkjr3uqcaGVEb1TSIqLIS3BR8AYZozqzaSBmXhFWLBmNxeM69dkkYwrTsiz6+d+dI1dYnHa7TDsTNi13E73vP4tO83D0NPtgutKqW4tkokgH8gJ2+5Py6qf7wHTAYwxn4lIPJAFtL7CxdfRhXoNLc8v46rHF/PT04dx64vtX03N6xEEO/d6dV2AU0f25Jvj+x9wTdPvneSsjRsM2jV2P74b1syFqmLwxsHImXaNXY/XrsQG0Lftqh6lVPcTyUSwCBgqIgOBAmAWcGmzY7YDpwKPichIIB4ojkg0XaBEsK20ivfXFfPLuXbd2/Ak0C8tgcRYL3lZSVTXBejVI54fnzaUn72wnBmjexPv83LxhJy2Tn1wL19jp3MAGDwNhk2H0Rc1XaBFKeVKEUsExhi/iFwPvIXtGvqIMWaViPwKWGyMmQvcCDwkIj/BVhtdYSI9wq2TE8Hnm0u59KHPifHYqQ/CDe+Vwnnj+pKa4GPWxNxWv9k/PWdy+y9WVQIx8XbFrWAQ5t1oR1MDrHoJco6Dk38GQ07tsnP5K6U6X0THEThjAuY123dH2PPVwInN3xcRnVA1VLSvhtKqOv753kaSY2PIzUxsWGc1PAlcPWUg/3P2UV//gnX74ct/21k9t38O69+0+3NPgLpKKFxuP3eP/jB2Nsz4Y9vLMiqlXMuFI4sjUyLYXFzJ+fd+wr4af5P9aYk+4mO8/O3bxzApLwMROWCd/kHVV8OaV+3i6yv/a+f3B/v5xs22q3ztXGqTw6gL4VsP67d/pdQBaSL4mvyBINP++gHb9zSu9zptRE9+OG0IibEx5GUlEhfzNSe589fab/t7NsMHf7azegIkZcO5/wu9RkHGoMb6/ppy2xto+FmaBJRSB6WJ4DAEgoaVBeVsKKrkpue/atg/oncKv71glG+R5qAAABjeSURBVLPodwdZPx+euqhxO2MQHH89DP4GpA9s/UYfn2qneFZKqXZwUSLouJHF//5sa8NKVwBDeiZz2XG5XHniwK99bmr22aUbB06BorXw6g12/+BpcMIP7fKOcTpaVynVcVyUCL7+yOKa+gAPfriZpxduByA3I5FHrpjIkJ6H0ABbXwNfPW1v7Cm9weOzC7YYA1/cD+//3lbtxKZAnTPU95sP2SUdlVIqAtyXCA6zRLBjz36m/Om9hu3HrpzI1OE9D+0kBUtg/h2w7ePGfYNPhQsfsSN937wVEjLgG7+A3SuhYhecfLMd4auUUhHiwkRw6CWCPVV1TZKA1yOHngR2fQUPTbPPp/0CitfDiudg0zvwxwF2f4/+8MPF4Eto+zxKKdXBXJQIDq+NwBjDlY8uBOCumEe5NO4TfIH98PrVcPZfmh8Mix+BhQ/ZRdqHz4BJc6B+P7z6Izulw7WfNM7fc9699vg3b7FJ4IrXNAkopTqdexIBh5cIfvbCcr7KL2eo5HN5zAIIOC8segiCfjj7r41rIL/0/cZpHMBWAb3/B1vXL16Y+Y+mk7jFxMLka2Di92x8Xhf9cyilugz3LPl0GFVDawv38fySfADePKMMEPjxSrjKmaZ5yaPwxs9s//65NzQmgWs/hV+Wwal32BG+PY+Gix6FcZe1fiGvT5OAUipq3HP3OcTG4gWrd3P1v+2qXKcNTcW74hnbdTMtx/7csMwmgUUP25+Qq96xUzkDTLkRJn1fp3VQSnVpmgjATsuQ0gdi7TKPC1bv5sbn7NQNfVLjeWD0Wpi3Gab/sfE9GQPh0uegcIUtCXhiYOpt4Itvem5NAkqpLs5FiaCNNoJ9O+Ef46HXaLj2Y7aWVDHnP4sZ3iuFV2Yfy4CMRDzPXgoZg1t24xSBPmPsj1JKHaHc10bQfEDZhgX2cfcKKNnAml37MAb+ctExDMxKwuMRKFwJfcfpvD1KqW7JfYmgtRKBoz5/Kdc+aZeAHJiVZHdW74Xy7Y2rdymlVDejiaBip53OAVi/zq4cdvKwbJLinFqzwpX2sfeozohSKaU6nQsTQbOqoYpCyByEScpmzZoVpMTF8OgVExtfL3SWk+yt7QBKqe7JPY3FbQ0oqyqBpGyq6wJk7CvllJHZTReO2b0SkntB8iFOKaGUUkcIF5UIQomgWYmgpgzi0yghjSwp55fnHt309eK10HNk58SolFJR4KJE0EYbQfVeSEinyKTSy1NOdkpc09f3boP0vE4JUSmlosHdiSAYtHP/J6SRX59CJuV2X0htJewvgbTczo1VKaU6kbsTQV0FmCDlJLGyPJ4YAraEEFK+wz6mDei8OJVSqpO5KBG00lhcUw7A6+v3U2TS7L7K3Y2v791mHzURKKW6MRclglZGFtfXAPDZ9v2cMGaE3VdV1Ph6mV2SknRNBEqp7st9iSCsRPC7V5cCUIuP804aZ3dWhiWCPZvAlwRJ2Z0VpVJKdToXJgJbItiwu4JFG3YBcM1po0jI6Gdf31fQ+J6S9XYhGZ1jSCnVjbkwEdgSwdLtZcRJPQAjcrIhLgUS0qFsR+N7itdD9vDOjlQppTqVexJBiJMI1u2uIEHqAEhMcCaYS81p7ClUWwn78psuLamUUt2QexJBs6qhdYUVDM3w2X0xziCyjEF2JDHYaiGALC0RKKW6NxcmgsYSQW6qs+h8jLOqWP+JtqdQZVFjItCqIaVUN+fKRFBV66e4opa+SU4jcKhEkDPJPu5YCMXr7PKTGYM6P1allOpE7pl9NGxAWWmlbRtI9QXsvlCJoM8x4I2FLR/Cpneg51Hg9UUhWKWU6jwuSgSNA8pKqmoB6OFzxhSESgQxcTYZLHzAbs9+sXNjVEqpKHBl1dAep0SQ7PXbfaESAUDuZGdfAgye1okBKqVUdEQ0EYjIdBFZJyIbReTWNo65WERWi8gqEXkqcsE0JoJSp0SQ6KkHxFYHhYy+2O4bc5EOJFNKuULEqoZExAvcC5wO5AOLRGSuMWZ12DFDgduAE40xe0UkcsuAhXUfzS+rxiNOiSAmvukNv88YuHGdTiuhlHKNSJYIJgEbjTGbjTF1wDPAec2OuRq41xizF8AYU0TENDYWbympon96It5AXWP7QLiUXuBxT62ZUsrdInm36weEzddAvrMv3DBgmIh8IiKfi8j0iEUTtlTl1tIq8rKSwF/TtH1AKaVcKJKJoLUK9mYLBhMDDAWmApcAD4tIWosTicwRkcUisri4uPgwo7Ef1ZgAW0v2MzAzEfy1rZcIlFLKRQ6aCETkehFJP4xz5wM5Ydv9gZ2tHPOKMabeGLMFWIdNDE0YYx40xkwwxkzIzj7MunsnEVTV1FNZ69cSgVJKOdpTIuiNbeh9zukF1N6uNIuAoSIyUERigVnA3GbHvAx8A0BEsrBVRZvbef5D4ySCkopqAAZnJ2uJQCmlaEciMMb8Avst/V/AFcAGEfmdiAw+yPv8wPXAW8Aa4DljzCoR+ZWIzHQOewsoFZHVwHvAzcaY0sP+NAfi5K+ifTYRjOzTA/zVWiJQSrleu7qPGmOMiBQChYAfSAdeEJEFxpifHeB984B5zfbdEX5e4KfOT2Q5JYK9VbWkJvjITomzJQKfJgKllLsdNBGIyA3A5UAJ8DD2W3u9iHiADUCbiaBLcRJBda3fJgGwbQRxKVEMSimloq89JYIs4JvGmG3hO40xQRE5JzJhRUAoEdTVk5HijCTWNgKllGpXY/E8YE9oQ0RSROQ4AGPMmkgF1uGcRFBTV09WcigRaK8hpZRqTyK4D6gM265y9h1hbGNxTb2fjCQtESilVEh7EoE4jbqArRLiSJy+2uk15A8ESIpzwtcSgVJKtSsRbBaRG0TE5/z8iEj19Y8kEQxCMBgk0RdKBLWaCJRSrteeRHANcAJQgB0JfBwwJ5JBRYx48GBIiHU+dn21Vg0ppVzvoFU8zoygszohlsgTwUOQBJ8XAn4wAS0RKKVcrz3jCOKB7wFHAw13TWPM/4tgXBHiQYB4n9e2D4AmAqWU67Wnaug/2PmGzgQ+wE4eVxHJoCLFiDhVQ17bPgCaCJRSrteeRDDEGHM7UGWMeRw4Gxgd2bAiw4gHCVUNNZQItI1AKeVu7UkE9c5jmYiMAlKBvIhFFFGesBKBVg0ppRS0bzzAg856BL/ATiOdDNwe0agixIBNBL7wqiEtESil3O2AicCZWG6fs6bwh8CgTokqQmzVUKhEYKej1hKBUsrtDlg15Iwivr6TYok4gyAYkmJjtESglFKO9rQRLBCRm0QkR0QyQj8RjywCgnjwECQ5LkYbi5VSytGeNoLQeIHrwvYZjsBqoiC2+2hinBeCAbvTGxvdoJRSKsraM7J4YGcE0hkMECOGuBgvBJzOUB5vVGNSSqloa8/I4u+2tt8Y8++ODyeygsaDzyvOht8+enzRC0gppbqA9lQNTQx7Hg+cCnwJHHmJACE2VAAIhkoER96M2kop1ZHaUzX0w/BtEUnFTjtxxAkYIdbjlAgCTonAqyUCpZS7tafXUHP7gaEdHUhnCCL4vM4aOw1VQ9pGoJRyt/a0EbyKbWcFmziOAp6LZFCREjQQWoqgsWpISwRKKXdrTwX5X8Ke+4Ftxpj8CMUTUQEj+DzNG4u1jUAp5W7tuQtuB3YZY2oARCRBRPKMMVsjGlkEBBB8oZogbSNQSimgfW0EzwPBsO2As++IY0sEzoa2ESilFNC+RBBjjKkLbTjPj8jhuAEDPk+osVjbCJRSCtqXCIpFZGZoQ0TOA0oiF1JkbCyqJGiEGG0jUEqpJtpzF7wGeFJE/uls5wOtjjbuyl5eWsBMhIQYHUeglFLh2jOgbBMwWUSSATHGHJHrFd94xjDq1iXjS3VmGw36QbwgEt3AlFIqyg5aNSQivxORNGNMpTGmQkTSReQ3nRFcRxIR4nw+PIS1EWi1kFJKtauNYIYxpiy04axWdlbkQookAeN0gAoGtFpIKaVoXyLwikjD6i0ikgAcmau5iIBxSgSBeu06qpRStK+x+AngHRF51Nm+Eng8ciFFkHjCSgR+7TqqlFK0r7H4TyKyHDgNEOBNYECkA4uIJolA2wiUUgraP/toIXZ08bew6xGsac+bRGS6iKwTkY0icusBjrtQRIyITGhnPIenSSLQNgKllIIDlAhEZBgwC7gEKAWexXYf/UZ7TiwiXuBe4HTs2INFIjLXGLO62XEpwA3AF4f1CQ6FhDUWaxuBUkoBBy4RrMV++z/XGHOSMeYf2HmG2msSsNEYs9mZluIZ4LxWjvs18Ceg5hDOfXjEQ8OM2tpGoJRSwIETwbewVULvichDInIqto2gvfoBO8K28519DURkHJBjjHntQCcSkTkislhEFhcXFx9CCM1PpG0ESinVXJuJwBjzkjHm28AI4H3gJ0AvEblPRM5ox7lbSxqm4UURD/B34MaDncgY86AxZoIxZkJ2dnY7Lt1WRJ7G7qPBAHg1ESil1EEbi40xVcaYJ40x5wD9gWVAmw2/YfKBnLDt/sDOsO0UYBTwvohsBSYDcyPbYNy8jUATgVJKHdKaxcaYPcaYB4wx09px+CJgqIgMFJFYbMPz3LBzlRtjsowxecaYPOBzYKYxZvGhxHRIwhuLtY1AKaWAw1u8vl2MMX7geuAtbHfT54wxq0TkV+HTWneqJlVDfi0RKKUU7RtZfNiMMfOAec323dHGsVMjGQvQcmSxjiNQSqnIlQi6pPBEoG0ESikFuC4RaBuBUko157JE0HxAmZYIlFLKfYkgvGpIxxEopZSLE4GWCJRSCnBlIghfqlLbCJRSyl2JAJpOQ60lAqWUclkiCC8RaBuBUkoBrkwE2kaglFLhXJ4ItI1AKaVcngh0hTKllHJZImg2DbXONaSUUm5LBLpUpVJKNee+RGCCtusoRhuLlVIKVyYCY0sDoN1HlVIKtyWC0FKVgXq7qSUCpZRyWSIINRaHSgTaRqCUUm5LBM2qhrREoJRSbkwEQW0jUEqpMO5MBNpGoJRSDVyWCLSNQCmlmnNZInAGlGkbgVJKNXBfItA2AqWUasKFicBoG4FSSoVxYSLQNgKllArnrkQAzRKBlgiUUspdiUDnGlJKqRZcmAh0HIFSSoVzZyIIhhKBthEopZRLE0HAbmuJQCml3JYImk1DrW0ESinltkSgI4uVUqo5FyYCwhqLtY1AKaVcmgjq7KPHG71YlFKqi4hoIhCR6SKyTkQ2isitrbz+UxFZLSLLReQdERkQyXhA7EOg1j56tUSglFIRSwQi4gXuBWYARwGXiMhRzQ5bCkwwxowBXgD+FKl4nKDso44jUEqpBpEsEUwCNhpjNhtj6oBngPPCDzDGvGeM2e9sfg70j2A8rVQNaYlAKaUimQj6ATvCtvOdfW35HvBGBOPRNgKllGpFJOtGpJV9ptUDRWYDE4BT2nh9DjAHIDc392tE5CQCv5MItI1AKaUiWiLIB3LCtvsDO5sfJCKnAf8DzDTG1LZ2ImPMg8aYCcaYCdnZ2YcfUUMbgVYNKaVUSCQTwSJgqIgMFJFYYBYwN/wAERkHPIBNAkURjMW5YPOqIW0sVkqpiCUCY4wfuB54C1gDPGeMWSUivxKRmc5hfwaSgedFZJmIzG3jdB2jxYAybSNQSqmIfiU2xswD5jXbd0fY89Mief0WGhJBrS0NSGvNGEop5S4uHVlcr+0DSinlcFciCAnUafuAUko53JUIwhuLdQpqpZQC3JoI/FoiUEqpEHcmgkCdthEopZTDxYlASwRKKQWuSwRhI4u1jUAppQDXJQItESilVHMuTQQ6jkAppULcmQj8tTq9hFJKOdyVCAhvI9ASgVJKgdsSQfhSldpGoJRSgOsSQfikc1oiUEopcG0iqNc2AqWUcrgzEfhrtWpIKaUc7kwEgVrwJUQ3FqWU6iLclQhi4hufayJQSinAbYnAp4lAKaWac1ciiAm7+fsSoxeHUkp1Ie5KBFoiUEqpFtyVCJq0EWiJQCmlwG2JILwUoCUCpZQC3JYIwksE4c+VUsrF3JUIfNpYrJRSzbkrEeg4AqWUasFdiSA0+yhASp/oxaGUUl2IuxJBuNT+0Y5AKaW6BPcmAi0RKKUUAO6bgvOqd2HHF+B130dXSqnWuO9u2P9Y+6OUUgpwc9WQUkopQBOBUkq5niYCpZRyOU0ESinlcpoIlFLK5TQRKKWUy2kiUEopl9NEoJRSLifGmGjHcEhEpBjYdphvzwJKOjCcjqJxHbquGpvGdWg0rkPzdeIaYIzJbu2FIy4RfB0istgYMyHacTSncR26rhqbxnVoNK5DE6m4tGpIKaVcThOBUkq5nNsSwYPRDqANGteh66qxaVyHRuM6NBGJy1VtBEoppVpyW4lAKaVUM5oIlFLK5VyTCERkuoisE5GNInJrJ1/7EREpEpGVYfsyRGSBiGxwHtOd/SIi9zhxLheR8RGMK0dE3hORNSKySkR+1BViE5F4EVkoIl85cd3l7B8oIl84cT0rIrHO/jhne6Pzel4k4gqLzysiS0Xkta4Sl4hsFZEVIrJMRBY7+7rC31iaiLwgImudv7Pjox2XiAx3fk+hn30i8uNox+Vc6yfO3/xKEXna+b8Q+b8vY0y3/wG8wCZgEBALfAUc1YnXPxkYD6wM2/cn4Fbn+a3AH53nZwFvAAJMBr6IYFx9gPHO8xRgPXBUtGNzzp/sPPcBXzjXew6Y5ey/H7jWef4D4H7n+Szg2Qj/e/4UeAp4zdmOelzAViCr2b6u8Df2OHCV8zwWSOsKcYXF5wUKgQHRjgvoB2wBEsL+rq7ojL+viP6Su8oPcDzwVtj2bcBtnRxDHk0TwTqgj/O8D7DOef4AcElrx3VCjK8Ap3el2IBE4EvgOOyIypjm/6bAW8DxzvMY5ziJUDz9gXeAacBrzs2hK8S1lZaJIKr/jkAP58YmXSmuZrGcAXzSFeLCJoIdQIbz9/IacGZn/H25pWoo9AsOyXf2RVMvY8wuAOexp7M/KrE6xcpx2G/fUY/NqX5ZBhQBC7AlujJjjL+VazfE5bxeDmRGIi7gbuBnQNDZzuwicRlgvogsEZE5zr5o/zsOAoqBR52qtIdFJKkLxBVuFvC08zyqcRljCoC/ANuBXdi/lyV0wt+XWxKBtLKvq/ab7fRYRSQZ+C/wY2PMvgMd2sq+iMRmjAkYY8Ziv4FPAkYe4NqdEpeInAMUGWOWhO+OdlyOE40x44EZwHUicvIBju2suGKwVaL3GWPGAVXYKpdox2UvZuvaZwLPH+zQVvZF4u8rHTgPGAj0BZKw/55tXbvD4nJLIsgHcsK2+wM7oxRLyG4R6QPgPBY5+zs1VhHxYZPAk8aYF7tSbADGmDLgfWzdbJqIxLRy7Ya4nNdTgT0RCOdEYKaIbAWewVYP3d0F4sIYs9N5LAJewibPaP875gP5xpgvnO0XsIkh2nGFzAC+NMbsdrajHddpwBZjTLExph54ETiBTvj7cksiWAQMdVrfY7HFwblRjmkucLnz/HJs/Xxo/3edngqTgfJQcbWjiYgA/wLWGGP+1lViE5FsEUlznidg/4OsAd4DLmwjrlC8FwLvGqfitCMZY24zxvQ3xuRh/4beNcZcFu24RCRJRFJCz7H13iuJ8r+jMaYQ2CEiw51dpwKrox1XmEtorBYKXT+acW0HJotIovN/M/T7ivzfVyQbYrrSD7blfz22rvl/OvnaT2Pr/OqxWfx72Lq8d4ANzmOGc6wA9zpxrgAmRDCuk7BFyeXAMufnrGjHBowBljpxrQTucPYPAhYCG7HF+Thnf7yzvdF5fVAn/JtOpbHXUFTjcq7/lfOzKvT3He1/R+daY4HFzr/ly0B6F4krESgFUsP2dYW47gLWOn/3/wHiOuPvS6eYUEopl3NL1ZBSSqk2aCJQSimX00SglFIup4lAKaVcThOBUkq5nCYCpTqRiEwVZ9ZSpboKTQRKKeVymgiUaoWIzBa7JsIyEXnAmQSvUkT+KiJfisg7IpLtHDtWRD535qp/KWwe+yEi8rbYdRW+FJHBzumTpXGO/iedUaRKRY0mAqWaEZGRwLexE7mNBQLAZdhJwL40dnK3D4BfOm/5N3CLMWYMduRpaP+TwL3GmGOwc8aEpiUYB/wYu/bDIOwcRkpFTczBD1HKdU4FjgUWOV/WE7ATkAWBZ51jngBeFJFUIM0Y84Gz/3HgeWfun37GmJcAjDE1AM75Fhpj8p3tZdi1Kj6O/MdSqnWaCJRqSYDHjTG3Ndkpcnuz4w40P8uBqntqw54H0P+HKsq0akiplt4BLhSRntCw9u8A7P+X0CyQlwIfG2PKgb0iMsXZ/x3gA2PXdcgXkfOdc8SJSGKnfgql2km/iSjVjDFmtYj8Arvilwc7a+x12IVVjhaRJdjVoL7tvOVy4H7nRr8ZuNLZ/x3gARH5lXOOizrxYyjVbjr7qFLtJCKVxpjkaMehVEfTqiGllHI5LREopZTLaYlAKaVcThOBUkq5nCYCpZRyOU0ESinlcpoIlFLK5f4/LpGzOxPh47AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25c96cc2048>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(history.history['val_accuracy'])\n",
    "#print(history.history['accuracy'])\n",
    "\n",
    "ta = pd.DataFrame(history.history['accuracy'])\n",
    "va = pd.DataFrame(history.history['val_accuracy'])\n",
    "\n",
    "tva = pd.concat([ta,va] , axis=1)\n",
    "\n",
    "tva.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9910200e-01, 8.9805364e-04], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1365  220]\n",
      " [ 156  259]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88      1585\n",
      "           1       0.54      0.62      0.58       415\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.72      0.74      0.73      2000\n",
      "weighted avg       0.82      0.81      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = []\n",
    "for val in predictions:\n",
    "    y_pred.append(np.argmax(val))\n",
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "cr=metrics.classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
